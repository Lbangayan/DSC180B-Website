{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53273d76",
   "metadata": {},
   "source": [
    "\n",
    "# Probing LLaMA for Gradient-Descent-Like In‑Context Learning (ICL)\n",
    "\n",
    "This notebook reproduces the core evaluation ideas of **\"Transformers Learn In-Context by Gradient Descent\"** (ICML 2023) — but instead of training small Transformers from scratch, we test whether a pre-trained LLaMA-style model performs gradient-descent-like in-context learning on synthetic regression tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df9e50",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31e1ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "MODEL_NAME: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# If running in a fresh environment, uncomment this cell.\n",
    "# %pip install -q transformers accelerate einops torch torchvision torchaudio\n",
    "\n",
    "import os, math, re, json, random, time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"      # prevents HF Transformers from importing TensorFlow backend\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"    # hide TF logs if it still gets imported somehow\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # cleaner logs\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MODEL_NAME = os.environ.get(\"LLAMA_MODEL\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"MODEL_NAME:\", MODEL_NAME)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(  # Renamed to llama_model\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    ")\n",
    "llama_model.to(device)\n",
    "llama_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0849a5a",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Task generators and baselines\n",
    "We follow the paper's setup: draw a random linear teacher `W` and sample inputs `x ~ U(-α, α)`. Then `y = W x` (no noise for simplicity).\n",
    "\n",
    "We compute:\n",
    "- GD-1: One step of gradient descent on the MSE loss starting from `W0 = 0`.\n",
    "- GD++: A simple curvature-heuristic variant using a Gram-matrix preconditioning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baaa302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_DEFAULT = 20  # change this once and reuse\n",
    "SEED = 42       # set None for nondeterministic sampling\n",
    "\n",
    "rng_global = np.random.default_rng(SEED)\n",
    "\n",
    "@dataclass\n",
    "class LinearTask:\n",
    "    W: np.ndarray         # shape: (1, d)\n",
    "    X: np.ndarray         # shape: (N, d)\n",
    "    y: np.ndarray         # shape: (N,)\n",
    "    x_test: np.ndarray    # shape: (d,)\n",
    "    y_test: float         # scalar\n",
    "\n",
    "def sample_linear_task(\n",
    "    d: int = D_DEFAULT,\n",
    "    N: Optional[int] = None,\n",
    "    alpha: float = 1.0,\n",
    "    rng: Optional[np.random.Generator] = None,\n",
    ") -> LinearTask:\n",
    "    \"\"\"\n",
    "    Sample a noiseless linear regression task:\n",
    "        y = W x,  x ~ U(-alpha, alpha)^d\n",
    "    Defaults to N = 2d + 1 in-context examples to match the paper.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = rng_global\n",
    "    if N is None:\n",
    "        N = 2 * d + 1\n",
    "\n",
    "    # Teacher\n",
    "    W = rng.standard_normal(size=(1, d))        # shape (1, d)\n",
    "\n",
    "    # Context inputs and targets\n",
    "    X = rng.uniform(-alpha, alpha, size=(N, d)) # (N, d)\n",
    "    y = (W @ X.T).reshape(-1)                   # (N,)\n",
    "\n",
    "    # Query\n",
    "    x_test = rng.uniform(-alpha, alpha, size=(d,))\n",
    "    y_test = float(W @ x_test)\n",
    "\n",
    "    return LinearTask(W=W, X=X, y=y, x_test=x_test, y_test=y_test)\n",
    "\n",
    "def gd1_predict(X: np.ndarray, y: np.ndarray, x_test: np.ndarray, eta: float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    One GD step on MSE with W0 = 0:\n",
    "        W1 = (eta/N) sum_i y_i x_i^T\n",
    "        y_hat = W1 x_test = (eta/N) sum_i y_i <x_i, x_test>\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    return float((eta / N) * np.sum(y * (X @ x_test)))\n",
    "\n",
    "def gdpp_predict(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    x_test: np.ndarray,\n",
    "    eta: float = 1.0,\n",
    "    gamma: float = 0.0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Simple GD++-style preconditioning via Gram matrix G = X X^T:\n",
    "        w = (I - gamma * G) y\n",
    "        y_hat = (eta/N) sum_i w_i <x_i, x_test>\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    G = X @ X.T                       # (N, N)\n",
    "    w = y - gamma * (G @ y)           # (N,)\n",
    "    return float((eta / N) * np.sum(w * (X @ x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b90ea",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Prompt construction for LLaMA\n",
    "We format the context as pairs on separate lines, then ask for a numeric prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72a364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_pair(x: np.ndarray, y: float) -> str:\n",
    "    xs = \", \".join(f\"{v:.6f}\" for v in x.tolist())\n",
    "    return f\"({xs}) -> {y:.6f}\"\n",
    "\n",
    "def build_prompt_linear(task: LinearTask, style: str = \"json\") -> str:\n",
    "    header = \"You are solving a noiseless linear regression task: y = W · x.\\n\"\n",
    "    header += \"Given N training pairs, predict y for the query x_test.\\n\\n\"\n",
    "    lines = [format_pair(task.X[i], task.y[i]) for i in range(task.X.shape[0])]\n",
    "    ctx = \"\\n\".join(lines)\n",
    "    xs_test = \", \".join(f\"{v:.6f}\" for v in task.x_test.tolist())\n",
    "\n",
    "    if style == \"json\":\n",
    "        prompt = (\n",
    "            header\n",
    "            + \"Training pairs (each line is '(x1, ..., xd) -> y'):\\n\"\n",
    "            + ctx + \"\\n\\n\"\n",
    "            + f\"Now predict for x_test = [{xs_test}].\\n\"\n",
    "            + \"Respond with a single number only. If you prefer, return JSON: {\\\"y\\\": <number>}\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            header + ctx + \"\\n\\n\"\n",
    "            + f\"Predict y when x = ({xs_test}).\\n\"\n",
    "            + \"Answer with a single number.\"\n",
    "        )\n",
    "    return prompt\n",
    "\n",
    "FLOAT_RE = re.compile(r\"[-+]?(?:\\d*\\.\\d+|\\d+)(?:[eE][-+]?\\d+)?\")\n",
    "\n",
    "def parse_numeric(text: str) -> Optional[float]:\n",
    "    try:\n",
    "        j = json.loads(text.strip().splitlines()[-1])\n",
    "        if isinstance(j, dict):\n",
    "            for k in [\"y\", \"value\", \"answer\", \"prediction\"]:\n",
    "                if k in j:\n",
    "                    return float(j[k])\n",
    "        elif isinstance(j, (int, float)):\n",
    "            return float(j)\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = FLOAT_RE.search(text)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(0))\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ee387",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Running the model\n",
    "We perform greedy decoding to encourage a single numeric answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b038037",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def llama_predict(prompt: str, max_new_tokens: int = 32, temperature: float = 0.0) -> Tuple[str, Optional[float]]:\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    gen = llama_model.generate(  # Using llama_model instead of model\n",
    "        **input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=temperature > 0.0,\n",
    "        temperature=max(temperature, 1e-5),\n",
    "        top_p=1.0,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    out = tokenizer.decode(gen[0][input_ids[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "    val = parse_numeric(out)\n",
    "    return out, val\n",
    "\n",
    "def mse(a: List[float], b: List[float]) -> float:\n",
    "    a = np.array(a, dtype=float); b = np.array(b, dtype=float)\n",
    "    return float(np.mean((a - b)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78fa91",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Evaluation on many tasks\n",
    "We will measure MSE for LLaMA, GD-1, and GD++; and estimate finite-difference sensitivities for alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19e478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def finite_diff_sensitivity(task: LinearTask, eps: float = 1e-3, temperature: float = 0.0) -> Optional[np.ndarray]:\n",
    "    base_prompt = build_prompt_linear(task, style=\"json\")\n",
    "    _, base_val = llama_predict(base_prompt, temperature=temperature)\n",
    "    if base_val is None:\n",
    "        \n",
    "        return None\n",
    "    d = task.x_test.shape[0]\n",
    "    sens = np.zeros(d, dtype=float)\n",
    "    for j in range(d):\n",
    "        x_pert = task.x_test.copy()\n",
    "        x_pert[j] += eps\n",
    "        t2 = LinearTask(W=task.W, X=task.X, y=task.y, x_test=x_pert, y_test=float(task.W @ x_pert))\n",
    "        p2 = build_prompt_linear(t2, style=\"json\")\n",
    "        _, v2 = llama_predict(p2, temperature=temperature)\n",
    "        if v2 is None:\n",
    "            return None\n",
    "        sens[j] = (v2 - base_val) / eps\n",
    "    return sens\n",
    "\n",
    "def eval_linear_suite(n_tasks: int = 20, d: int = 10, N: int = 10, alpha: float = 1.0,\n",
    "                      eta_gd: float = 1.0, use_gdpp: bool = False, gamma: float = 0.0,\n",
    "                      temperature: float = 0.0, do_sensitivity: bool = True) -> Dict[str, Any]:\n",
    "    gt_list, llama_list, gd_list, gdpp_list = [], [], [], []\n",
    "    cos_sims, sens_norms = [], []\n",
    "    failures = 0\n",
    "\n",
    "    for _ in range(n_tasks):\n",
    "        task = sample_linear_task(d=d, N=N, alpha=alpha)\n",
    "        prompt = build_prompt_linear(task, style=\"json\")\n",
    "        txt, pred = llama_predict(prompt, temperature=temperature)\n",
    "        if pred is None or not np.isfinite(pred):\n",
    "            failures += 1\n",
    "            continue\n",
    "\n",
    "        gt = task.y_test\n",
    "        gdhat = gd1_predict(task.X, task.y, task.x_test, eta=eta_gd)\n",
    "        gdpphat = gdpp_predict(task.X, task.y, task.x_test, eta=eta_gd, gamma=gamma) if use_gdpp else gdhat\n",
    "\n",
    "        gt_list.append(gt); llama_list.append(pred); gd_list.append(gdhat); gdpp_list.append(gdpphat)\n",
    "\n",
    "        if do_sensitivity:\n",
    "            sens = finite_diff_sensitivity(task, eps=1e-3, temperature=temperature)\n",
    "            if sens is not None and np.linalg.norm(sens) > 0:\n",
    "                gd_vec = (eta_gd / N) * (task.y[:, None] * task.X).sum(axis=0)\n",
    "                cos = float(np.dot(sens, gd_vec) / (np.linalg.norm(sens) * (np.linalg.norm(gd_vec) + 1e-9)))\n",
    "                cos_sims.append(cos)\n",
    "                sens_norms.append(float(np.linalg.norm(sens)))\n",
    "\n",
    "    results = {\n",
    "        \"failures\": failures,\n",
    "        \"MSE_llama\": mse(llama_list, gt_list) if llama_list else float(\"nan\"),\n",
    "        \"MSE_gd1\": mse(gd_list, gt_list) if gd_list else float(\"nan\"),\n",
    "        \"MSE_gdpp\": mse(gdpp_list, gt_list) if gdpp_list else float(\"nan\"),\n",
    "        \"mean_cosine_sensitivity\": mean(cos_sims) if cos_sims else float(\"nan\"),\n",
    "        \"mean_sensitivity_norm\": mean(sens_norms) if sens_norms else float(\"nan\"),\n",
    "        \"counts\": {\"evaluated\": len(gt_list), \"requested\": n_tasks}\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def tune_eta_gamma(val_tasks: int = 30, d: int = 10, N: int = 10, alpha: float = 1.0):\n",
    "    etas = np.linspace(0.2, 2.0, 10)\n",
    "    gammas = np.linspace(0.0, 0.2, 6)\n",
    "\n",
    "    def val_mse(eta, gamma):\n",
    "        mses = []\n",
    "        for _ in range(val_tasks):\n",
    "            t = sample_linear_task(d=d, N=N, alpha=alpha)\n",
    "            gdpp = gdpp_predict(t.X, t.y, t.x_test, eta=eta, gamma=gamma)\n",
    "            mses.append((gdpp - t.y_test)**2)\n",
    "        return float(np.mean(mses))\n",
    "\n",
    "    best_eta, best_gamma, best_mse = None, None, float(\"inf\")\n",
    "    for eta in etas:\n",
    "        for gamma in gammas:\n",
    "            m = val_mse(eta, gamma)\n",
    "            if m < best_mse:\n",
    "                best_eta, best_gamma, best_mse = eta, gamma, m\n",
    "    return {\"eta\": best_eta, \"gamma\": best_gamma, \"mse\": best_mse}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e8121",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Sanity run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e84e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\banga\\AppData\\Local\\Temp\\ipykernel_21872\\4249786493.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_test = float(W @ x_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned GD++ (rough): {'eta': 1.2, 'gamma': 0.0, 'mse': 0.8071709532047034}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "c:\\Users\\banga\\miniforge3\\envs\\dsc80\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:96: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\Users\\banga\\miniforge3\\envs\\dsc80\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:96: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "C:\\Users\\banga\\AppData\\Local\\Temp\\ipykernel_21872\\1123340506.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  t2 = LinearTask(W=task.W, X=task.X, y=task.y, x_test=x_pert, y_test=float(task.W @ x_pert))\n",
      "C:\\Users\\banga\\AppData\\Local\\Temp\\ipykernel_21872\\1123340506.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  t2 = LinearTask(W=task.W, X=task.X, y=task.y, x_test=x_pert, y_test=float(task.W @ x_pert))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {\n",
      "  \"failures\": 0,\n",
      "  \"MSE_llama\": 4.233942956153923,\n",
      "  \"MSE_gd1\": 1.6072235530873318,\n",
      "  \"MSE_gdpp\": 1.6072235530873318,\n",
      "  \"mean_cosine_sensitivity\": NaN,\n",
      "  \"mean_sensitivity_norm\": NaN,\n",
      "  \"counts\": {\n",
      "    \"evaluated\": 10,\n",
      "    \"requested\": 10\n",
      "  }\n",
      "}\n",
      "Elapsed: 188.5s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "tune = tune_eta_gamma(val_tasks=20, d=10, N=10, alpha=1.0)\n",
    "print(\"Tuned GD++ (rough):\", tune)\n",
    "\n",
    "res = eval_linear_suite(\n",
    "    n_tasks=10, d=10, N=10, alpha=1.0,\n",
    "    eta_gd=tune[\"eta\"], use_gdpp=True, gamma=tune[\"gamma\"],\n",
    "    temperature=0.0, do_sensitivity=True\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(\"Results:\", json.dumps(res, indent=2))\n",
    "print(f\"Elapsed: {elapsed:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd5bbb",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Out-of-distribution (OOD) scaling\n",
    "We vary the input range scale `α` and compare model MSE against GD-1 and GD++.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a87a0de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\banga\\AppData\\Local\\Temp\\ipykernel_13112\\4249786493.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_test = float(W @ x_test)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAGHCAYAAADoYMuVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnBUlEQVR4nO3dd1gUV9sG8Ht2gQWkKCJNEVCwa0SxYcGeRGNi1BhLLEFjwbyxJLG+saRA1MSYL4q9d5OY4htji4JdUcFeooIVRFEBpe+e7w9gZaUtZRnK/buuvdw9c2bmmQXPPJw5c0YSQggQERERFYFC7gCIiIio7GNCQUREREXGhIKIiIiKjAkFERERFRkTCiIiIioyJhRERERUZEwoiIiIqMiYUBAREVGRMaEgIiKiImNCQeXGiRMn8N5778HR0REmJiZwcHBAv379cPz48WJZZ+3atZAkSfsyNTWFg4MDOnXqhICAAERHR+sd65UrVzBkyBDUqlULpqamsLW1RbNmzfDxxx8jLi6uUMefn6CgIEiShKCgIG3Z7NmzIUmSQfZXWB07doQkSahVqxZymsj30KFD2p/B2rVrdZadPHkS7777LmrWrAmVSgV7e3u0adMGn376aY77yOnl6upqwKMrXq6urhg+fHih1h0+fDgsLCyKNyCq0JhQULnw008/oW3btrh37x7mzZuH/fv347vvvsP9+/fRrl07LFq0qFjWAYA1a9bg+PHj2LdvHxYvXoymTZti7ty5qF+/Pvbv359vrKGhoWjevDkuX76MmTNnYvfu3Vi6dCl69uyJPXv24MmTJ0X+PvQ1cuTIPBMuuVhaWiI8PBwHDhzItmz16tWwsrLKVv7XX3/B29sbcXFxmDdvHvbu3Ysff/wRbdu2xbZt27LVr1WrFo4fP57t9dtvvxnkmIjKPUFUxh05ckQoFArx1ltvidTUVJ1lqamp4q233hIKhUIcOXKkSOusWbNGABAhISHZYrh9+7ZwdnYWlpaWIioqKs94hw4dKipVqiTi4uJyXK7RaPI95sI4ePCgACAOHjxokO0XFx8fH9GwYUPRunVrMWjQIJ1lcXFxwtzcXHz00UcCgFizZo12WYcOHUTt2rWz/TyFEEKtVue4j7LOxcVFDBs2rFDrDhs2TFSqVKl4A6IKjT0UVOYFBARAkiQsWbIERkZGOsuMjIwQGBgISZLw7bffFmmdvNSsWRPff/894uPjsWzZsjzrxsTEwMrKKtfu5lcvQezevRtdunSBtbU1zM3NUb9+fQQEBGiXnz59GgMGDICrqyvMzMzg6uqKgQMH4vbt2/nGndMlD1dXV7z11lvYvXs3mjVrBjMzM9SrVw+rV6/Otv6RI0fQpk0bmJqaonr16vjiiy+wcuVKSJKEiIiIfPefF19fX+zYsQPPnj3Tlm3duhUAMGDAgGz1Y2JiYGtrm+3nCQAKRfE0dampqbCzs8OQIUOyLXv27BnMzMwwadIkAIBGo8HXX3+NunXrwszMDJUrV0aTJk3w448/5rmPpKQkfPrpp2jatCmsra1hY2ODNm3a4I8//sg3vszLWhs3bsSkSZPg4OAAMzMz+Pj4IDQ0NMd1bty4gR49esDCwgLOzs749NNPkZycrFNnzpw5aNWqFWxsbGBlZYVmzZph1apVOV6SooqLCQWVaWq1GgcPHoSXlxdq1KiRYx1nZ2c0b94cBw4cgFqtLtQ6+ujRoweUSiUOHTqUZ702bdogMjISgwcPRnBwMBITE3Otu2rVKvTo0QMajQZLly7Fzp078cknn+DevXvaOhEREahbty4WLlyIPXv2YO7cuYiMjESLFi3w+PFjvWJ/1blz5/Dpp59i4sSJ+OOPP9CkSROMGDFC59jOnz+Pbt26ISEhAevWrcPSpUtx9uxZfPPNN9m2lzn+5NUxD3kZMGAAlEoltmzZovN99OvXL8dLHm3atMHJkyfxySef4OTJk0hNTc13H2lpadleGo0m1/rGxsb44IMP8Ouvv2Yb67JlyxYkJSXhww8/BADMmzcPs2fPxsCBA/HXX39h27ZtGDFihE6ClJPk5GQ8efIEn332GX7//Xds2bIF7dq1Q58+fbB+/fp8jwkApk+fjlu3bmHlypVYuXIlHjx4gI4dO+LWrVs69VJTU/H222+jS5cu+OOPP+Dr64sffvgBc+fO1akXERGB0aNHY/v27dixYwf69OmD//znP/jqq6/0iocqCLm7SIiKIioqSgAQAwYMyLPe+++/LwCIhw8fFmodIfK+5JHJ3t5e1K9fP8/tJiUlid69ewsAAoBQKpXC09NTzJgxQ0RHR2vrxcfHCysrK9GuXbsCXQZJS0sTz58/F5UqVRI//vijtjynSx6zZs0SrzYDLi4uwtTUVNy+fVtblpiYKGxsbMTo0aO1Ze+9956oVKmSePTokbZMrVaLBg0aCAAiPDxcW75u3TqhVCrFunXr8o0/6+WIYcOGCS8vLyGEEJcuXRIARFBQkAgJCcl2yePx48eiXbt22u/V2NhYeHt7i4CAABEfH59tH5n1Xn2NGDEiz/jOnz8vAIjly5frlLds2VI0b95c+/mtt94STZs2zfd485OWliZSU1PFiBEjhKenp86yVy95ZP6MmzVrpvM7ExERIYyNjcXIkSO1ZcOGDRMAxPbt23W22aNHD1G3bt1c41Gr1SI1NVV8+eWXomrVqga7REdlD3soqEIQGV2zBbmjoSjr5EWlUuG3337D5cuX8cMPP2DAgAF49OgRvvnmG9SvXx/Xrl0DABw7dgxxcXHw8/PLM4bnz59jypQpcHd3h5GREYyMjGBhYYEXL17gypUreseeVdOmTVGzZk3tZ1NTU9SpU0fnMkpwcDA6d+4MW1tbbZlCoUD//v2zbW/o0KFIS0vD0KFDCxSHr68vTp8+jQsXLmDVqlWoXbs2OnTokGPdqlWr4vDhwwgJCcG3336Ld955B9evX8e0adPQuHHjbL01tWvXRkhISLbXF198kWdMjRs3RvPmzbFmzRpt2ZUrV3Dq1Cn4+vpqy1q2bIlz587Bz88Pe/bsKdDdOz///DPatm0LCwsLGBkZwdjYGKtWrdL75zlo0CCd3xkXFxd4e3vj4MGDOvUkSUKvXr10ypo0aZLtctmBAwfQtWtXWFtbQ6lUwtjYGDNnzkRMTEyB7m6i8o0JBZVptra2MDc3R3h4eJ71IiIiYG5uDhsbm0Kto48XL14gJiYGTk5OetWvX78+JkyYgI0bN+LOnTtYsGABYmJitCe0R48eAUCul2UyDRo0CIsWLcLIkSOxZ88enDp1CiEhIahWrVqel1PyUrVq1WxlKpVKZ3sxMTGwt7fPVi+nssLq0KEDPDw8sGzZMmzYsAG+vr75JnheXl6YMmUKfv75Zzx48AATJ05EREQE5s2bp1PP1NQUXl5e2V4uLi75xuXr64vjx4/j6tWrANLv/FGpVBg4cKC2zrRp0/Ddd9/hxIkTePPNN1G1alV06dIFp0+fznPbO3bsQP/+/VG9enVs3LgRx48fR0hICHx9fZGUlJRvbADg4OCQY1lMTIxOmbm5OUxNTXXKVCqVzn5OnTqF7t27AwBWrFiBo0ePIiQkBDNmzACAQv+OUfnDhILKNKVSiU6dOuH06dM64wqyunfvHs6cOYPOnTtDqVQWah19/PXXX1Cr1ejYsWOBj0OSJEycOBGVK1fGxYsXAQDVqlXTxpKb2NhY/O9//8PkyZMxdepUdOnSBS1atEDjxo0Nfvtp1apV8fDhw2zlUVFRxbqfDz/8EEuWLMGTJ08wbNiwAq1rbGyMWbNmAYD2ey0OAwcOhEqlwtq1a6FWq7Fhwwb07t0bVapU0dYxMjLCpEmTcPbsWTx58gRbtmzB3bt38frrryMhISHXbW/cuBFubm7Ytm0bevfujdatW8PLyyvbQMm85PQziIqKyjFRzM/WrVthbGyM//3vf+jfvz+8vb3h5eVV4O1Q+ceEgsq8adOmQQgBPz+/bAMo1Wo1xo4dCyEEpk2bVqR18nLnzh189tlnsLa2xujRo/OsGxkZmWP5gwcPEBcXp+3h8Pb2hrW1NZYuXZrrpRRJkiCEgEql0ilfuXKl3oNJC8vHxwcHDhzQuZSg0Wjw888/F+t+hg0bhl69euHzzz9H9erVc62X2/eaeZlA354jfVSpUgW9e/fG+vXr8b///Q9RUVE6lzteVblyZfTr1w/jxo3DkydP8rwDRpIkmJiY6PTEREVF6XWXR6YtW7bo/M7cvn0bx44dK3Sya2RkpJNYJyYmYsOGDQXeFpVv2e+vIipj2rZti4ULF2LChAlo164dPv74Y9SsWRN37tzB4sWLcfLkSSxcuBDe3t5FWifTxYsXtXcEREdH4/Dhw1izZg2USiV+++03bc9CbkaNGoVnz56hb9++aNSoEZRKJa5evYoffvgBCoUCU6ZMAQBYWFjg+++/x8iRI9G1a1d89NFHsLe3x40bN3Du3DksWrQIVlZW6NChA+bPnw9bW1u4uroiODgYq1atQuXKlYv1e37VjBkzsHPnTnTp0gUzZsyAmZkZli5dihcvXgDQvVVz/fr18PX1xerVqws8jsLJyQm///57vvVef/111KhRA7169UK9evWg0WgQFhaG77//HhYWFhg/frxO/cTERJw4cSLHbbVu3Trf/fn6+mLbtm34+OOPUaNGDXTt2lVnea9evdCoUSN4eXmhWrVquH37NhYuXAgXFxd4eHjkut233noLO3bsgJ+fH/r164e7d+/iq6++gqOjI/7999984wKA6OhovPvuu/joo48QGxuLWbNmwdTUVO8EOauePXtiwYIFGDRoEEaNGoWYmBh899132ZJYIt7lQeXG8ePHRb9+/YS9vb0wMjISdnZ2ok+fPuLYsWPFsk7mXR6ZLxMTE2FnZyd8fHyEv7+/zh0aedmzZ4/w9fUVDRo0ENbW1sLIyEg4OjqKPn36iOPHj2erv2vXLuHj4yMqVaokzM3NRYMGDcTcuXO1y+/duyf69u0rqlSpIiwtLcUbb7whLl68mOsdAPrc5dGzZ89scfj4+AgfHx+dssOHD4tWrVoJlUolHBwcxOeffy7mzp0rAIhnz55l++6y3pWRG30mncrpLo9t27aJQYMGCQ8PD2FhYSGMjY1FzZo1xZAhQ8Tly5ez7QO53OUBIMfJsV6lVquFs7OzACBmzJiRbfn3338vvL29ha2trTAxMRE1a9YUI0aMEBEREflu+9tvvxWurq5CpVKJ+vXrixUrVuT6s8rpZ7xhwwbxySefiGrVqgmVSiXat28vTp8+rbNubhNb5bSf1atXi7p16wqVSiVq1aolAgICxKpVq7LdzUMVmyQEZyYhouLTvXt3RERE4Pr163KHUuEEBQWhU6dO+Pnnn9GvXz+5w6EKhpc8iKjQJk2aBE9PTzg7O+PJkyfYtGkT9u3bh1WrVskdGhGVMCYURFRoarUaM2fORFRUFCRJQoMGDbBhwwZ88MEHcodGRCWMlzyIiIioyHjbKBERERUZEwoiIiIqMiYUREREVGTlflCmRqPBgwcPYGlpWaCHPBEREVV0QgjEx8fDyclJZ7K6nJT7hOLBgwdwdnaWOwwiIqIy6+7du/k+qLDcJxSWlpYA0r8MKysrmaMhIiIqO+Li4uDs7Kw9l+ZF9oTi/v37mDJlCv7++28kJiaiTp06WLVqFZo3bw4gvbtlzpw5WL58OZ4+fYpWrVph8eLFaNiwoV7bz7zMYWVlxYSCiIioEPQZMiDroMynT5+ibdu2MDY2xt9//43Lly/j+++/13mo0bx587BgwQIsWrQIISEhcHBwQLdu3RAfHy9f4ERERKRD1omtpk6diqNHj+Lw4cM5LhdCwMnJCRMmTNA+gTE5ORn29vaYO3duvo+JBtK7a6ytrREbG8seCiIiogIoyDlU1h6KP//8E15eXnjvvfdgZ2cHT09PrFixQrs8PDwcUVFR6N69u7ZMpVLBx8cHx44dy3GbycnJiIuL03kRERGRYck6huLWrVtYsmQJJk2ahOnTp+PUqVP45JNPoFKpMHToUERFRQEA7O3tddazt7fH7du3c9xmQEAA5syZU6A4hBBIS0uDWq0u3IFQgSmVShgZGfFWXiKickLWhEKj0cDLywv+/v4AAE9PT1y6dAlLlizB0KFDtfVePekIIXI9EU2bNg2TJk3Sfs4coZqblJQUREZGIiEhoSiHQoVgbm4OR0dHmJiYyB0KEREVkawJhaOjIxo0aKBTVr9+ffz6668AAAcHBwBAVFQUHB0dtXWio6Oz9VpkUqlUUKlUeu1fo9EgPDwcSqUSTk5OMDEx4V/MJUAIgZSUFDx69Ajh4eHw8PDId8IUIiIq3WRNKNq2bYtr167plF2/fh0uLi4AADc3Nzg4OGDfvn3w9PQEkN6jEBwcjLlz5xZ5/ykpKdBoNHB2doa5uXmRt0f6MzMzg7GxMW7fvo2UlBSYmprKHRIRUZmlTkvB2Qsb8CjuDqpZ1USzxkOgNCrZ3l9ZE4qJEyfC29sb/v7+6N+/P06dOoXly5dj+fLlANIvdUyYMAH+/v7w8PCAh4cH/P39YW5ujkGDBhVbHPzrWB783omIim7/kQB8e30THipf9rDbh/6AqXUGo2u7aSUWh6wJRYsWLfDbb79h2rRp+PLLL+Hm5oaFCxdi8ODB2jqTJ09GYmIi/Pz8tBNb7d27V69Zu4iIiMqz/UcCMOnGJohX/j6LVgCTbmzCAqDEkgpZ56EoCXndQ5uUlITw8HC4ubmxy10G/P6JiApPnZaC19c3w0MFgBzG/0lCwF4D7B56ttCXP8rMPBTlhVojcPxmDP4Iu4/jN2Og1pTrHI2IiEqBsxc2pF/myOVmAiFJiFJKOHthQ4nEw4SiiHZfjES7uQcwcMUJjN8ahoErTqDd3APYfTHSoPsdPnw4evfuneMyV1dXLFy4sNDbnj17NiRJwhtvvJFt2bx58yBJEjp27Jht2b1792BiYoJ69eoVet9ERKSfR3F3irVeUTGhKILdFyMxduNZRMYm6ZRHxSZh7MazBk8qDMnR0REHDx7EvXv3dMrXrFmDmjVr5rjO2rVr0b9/fyQkJODo0aMlESYRUYVVzSrntriw9YqKCcUrhBBISEnL9xWflIpZf15CThc3Mstm/3kZ8Umpem2vpIayqNVqjBgxAm5ubjAzM0PdunXx448/ZqtnZ2eH7t27Y926ddqyY8eO4fHjx+jZs2e2+kIIrFmzBkOGDMGgQYOwatUqgx4HEVFF16zxENirBZDL+UMSAg5qgWaNh5RIPLI/vry0SUxVo8HMPUXejgAQFZeExrP36lX/8pevw9zE8D8OjUaDGjVqYPv27bC1tcWxY8cwatQoODo6on///jp1fX19MXnyZMyYMQMAsHr1ap07cLI6ePAgEhIS0LVrV9SoUQOtWrXCjz/+yLtxiIgMRGlkgsF2rbAg5lR6UpFlLIWUkWRMqTO4xOajYA9FBWNsbIw5c+agRYsWcHNzw+DBgzF8+HBs3749W9233noLcXFxOHToEF68eIHt27fD19c3x+2uWrUKAwYMgFKpRMOGDeHu7o5t27YZ+nCIiCq0s0+uAABMX+mksNcAC9wr0DwUpZGZsRKXv3w933qnwp9g+JqQfOut/bAFWrrZ6LXfkrJ06VKsXLkSt2/fRmJiIlJSUtC0adNs9YyNjfHBBx9gzZo1uHXrFurUqYMmTZpkq/fs2TPs2LEDR44c0ZZ98MEHWL16NUaOHGnIQyEiqrAuXv4ZQSIeCiGw1edHPImNqLgzZZZGkiTpdemhvUc1OFqbIio2KcdxFBIAB2tTtPeoBqWi9DwfZPv27Zg4cSK+//57tGnTBpaWlpg/fz5OnjyZY31fX1+0atUKFy9ezLV3YvPmzUhKSkKrVq20ZUIIaDQaXL58OdvzWoiIqOgWh3wPAHjLxB61a3VBbZnj4SWPQlIqJMzqlX6ifDVdyPw8q1eDUpVMAMDhw4fh7e0NPz8/eHp6wt3dHTdv3sy1fsOGDdGwYUNcvHgx1+nOV61ahU8//RRhYWHa17lz59CpUyesXr3aUIdCRFRhnbu4FUfwAkohMKb9l3KHA4A9FEXyRiNHLPmgGebsvKxz66iDtSlm9WqANxo55rF20cXGxiIsLEynzMYm/fLK/fv3sy2rWbMm3N3dsX79euzZswdubm7YsGEDQkJC4Obmlut+Dhw4gNTUVFSuXDnbsrCwMJw9exabNm3KNv/EwIEDMWPGDAQEBMDY2LhQx0hERNkFnlkAAHhb5QBn57YyR5OOCUURvdHIEd0aOOBU+BNExyfBztIULd1sSqRnIigoSPsU1kzDhg0DAHz33Xf47rvvdJatWbMGY8aMQVhYGN5//31IkoSBAwfCz88Pf//9d677qVSpUq7LVq1ahQYNGuQ4mVXv3r0xduxY7Ny5E3369CnIoRERUS5Cz2/EMSTCSAiMav+13OFo8VkefJaEbPj9ExEV3Mh1LXASSehr4ojZA/WbmqCw+CwPIiKicigkbDVOIim9d8LHX+5wdDChICIiKiMCwwIBAH1NneHk5CVzNLqYUBAREZUBp0JX4rSUDGMhMLJjgNzhZMOEgoiIqJQTGg0Wn1sCAOhn5gIHh6byBpQDJhRERESl3PGzS3FWSoGJEBjZca7c4eSICQUREVEpJjQaBF5YCQDob+4GO/tGMkeUMyYUREREpdjR04txTpEKU43AiE7z5A4nV0woiIiISimh0WDxpfRHGLxv4Q7bavVljih3TCiIiIhKqcMhP+KiIg1mGoEPS3HvBMCpt4uHRg3cPgY8fwhY2AMu3oCi5B5HTkRE5Y/QaLD48jpAAQywqoOqtnXkDilP7KEoqst/AgsbAeveAn4dkf7vwkbp5QYWFRWF8ePHw93dHaamprC3t0e7du2wdOlSJCQkAABcXV0hSRIkSYKZmRlcXV3Rv39/HDhwIN/tJyUlYfjw4WjcuDGMjIzQu3dvAx8RERFlCjq5AJcVaphrBD7sNF/ucPLFhKIoLv8JbB8KxD3QLY+LTC83YFJx69YteHp6Yu/evfD390doaCj279+PiRMnYufOndi/f7+27pdffonIyEhcu3YN69evR+XKldG1a1d88803ee5DrVbDzMwMn3zyCbp27WqwYyEiIl0adRoWX90AABhkVQ9VbGrLHFH+eMnjVUIAqQn519Oogb8nA8jp2WoCgATsngLU6qjf5Q9jc0DS/wmlfn5+MDIywunTp3WeBtq4cWP07dsXWZ/5ZmlpCQcHBwDpjzDv0KEDHB0dMXPmTPTr1w9169bNcR+VKlXCkiXpE6kcPXoUz5490zs+IiIqvAPH5+OaQoNKGoFhnUt/7wTAhCK71ATA36kYNiTSey6+ddav+vQHgEnujwnPKiYmRtszkdujxaV8kpPx48fjq6++wh9//IHJkyfrFyMRERmcRp2GwH+3Agrgg8qNULmKm9wh6YWXPMqgGzduQAiRrWfB1tYWFhYWsLCwwJQpU/Lcho2NDezs7BAREWHASImIqKD2HQvAvwoNLDUCQzqX7js7smIPxauMzdN7C/Jz+xiwqV/+9Qb/kn7Xhz77LaBXeyFOnToFjUaDwYMHIzk5Od/1hRDabTRs2BC3b98GALRv3x5///13geMhIqKiUaelYMm/PwNKYEiVJrC2ril3SHpjQvEqSdLv0kPtzoCVU/oAzBzHUUjpy2t3LvZbSN3d3SFJEq5evapTXqtWLQCAmZlZvtuIiYnBo0eP4OaW3pW2a9cupKam6r0+EREVv71H/XFTKWCpEfigjIydyMRLHoWlUAJvZD6g5dXxChmf3/jWIPNRVK1aFd26dcOiRYvw4sWLQm3jxx9/hEKh0N4K6uLiAnd3d7i7u6N69erFGC0REelDnZaCwJs7AADDbDxhaVW22mImFEXR4G2g/3rAylG33MopvbzB2wbbdWBgINLS0uDl5YVt27bhypUruHbtGjZu3IirV69CqXyZyMTHxyMqKgp3797FoUOHMGrUKHz99df45ptv4O7unud+Ll++jLCwMDx58gSxsbEICwtDWFiYwY6LiKii2nX4S0QoBaw1AoPL0NiJTJLIen9hORQXFwdra2vExsbCyspKZ1lSUhLCw8Ph5uYGU1PTwu9EppkyIyMj4e/vj7/++gv37t2DSqVCgwYN8N5778HPzw/m5uZwdXXVjo0wMTGBg4MDWrdujTFjxqBTp0757iPr+lkVx69NsX3/RERlXFpqEnpvaIHbSmB8lWYY+fY6uUMCkPc59FUcQ1EcFErArX2J79bR0RE//fQTfvrpp1zrFPUuDt4FQkRkeH8dno3bSqCKRmBg57n5r1AK8ZIHERGRjFJTE7A04i8AwIfVWqGShYPMERUOEwoiIiIZ/S94Fu4pARuNwPtltHcCYEJBREQkm9TkF1h2ZzcAwNfOG+bmtjJHVHhMKIiIiGTye/B/cV8J2KoF+nf6Vu5wioQJBRERkQxSkuOx4t4+AMAIx3YwM7eROaKikTWhmD17NiRJ0nllPhUTSL81cfbs2XBycoKZmRk6duyIS5cuyRgxERFR8fgtaAYilRLs1AL9OgbIHU6Ryd5D0bBhQ0RGRmpfFy5c0C6bN28eFixYgEWLFiEkJAQODg7o1q0b4uPjZYyYiIioaJKTYrH8/gEAwEinjjA1qyJzREUne0JhZGQEBwcH7atatWoA0nsnFi5ciBkzZqBPnz5o1KgR1q1bh4SEBGzevFnmqImIiArv16DpiFZKsFcL9O1U9nsngFKQUPz7779wcnKCm5sbBgwYgFu3bgEAwsPDERUVhe7du2vrqlQq+Pj44NixY7luLzk5GXFxcTovIiKi0iIp8SlWPggGAIyq3gUmKkuZIyoesiYUrVq1wvr167Fnzx6sWLECUVFR8Pb2RkxMDKKiogAA9vb2OuvY29trl+UkICAA1tbW2pezs7NBjwEA1Bo1QqJCsOvWLoREhUCtURt8n0REVDb9fHAqHiklOKoF3u3oL3c4xUbWhOLNN99E37590bhxY3Tt2hV//ZU+U9i6dS/nMJck3Sd5CiGylWU1bdo0xMbGal937941TPAZ9t/ej9d/fR2+e3wx5fAU+O7xxeu/vo79t/cbdL8AEBUVhfHjx8Pd3R2mpqawt7dHu3btsHTpUiQkJABIfxZH5oBXMzMzuLq6on///jhw4IDB4yMiIl2JCU+wKuooAGCUc3cYqyrJHFHxkf2SR1aVKlVC48aN8e+//2rv9ni1NyI6Ojpbr0VWKpUKVlZWOi9D2X97PyYFTcLDhIe6MSZEY1LQJIMmFbdu3YKnpyf27t0Lf39/hIaGYv/+/Zg4cSJ27tyJ/ftf7vvLL79EZGQkrl27hvXr16Ny5cro2rUrvvnmm1y3HxQUBFdXV73jmT17NoYPH16EIyIiKv+2H5yCGKWE6mrgnY5fyx1OsSpVDwdLTk7GlStX0L59e7i5ucHBwQH79u2Dp6cnACAlJQXBwcGYO9dwU5MKIZCYlphvPbVGjYBTARDI/tTNzLJvT32LVg6toNTjyaNmRmZ59ry8ys/PD0ZGRjh9+jQqVXqZ4TZu3Bh9+/bVeRqopaWlNkGrWbMmOnToAEdHR8ycORP9+vVD3bp19d4vEREVTkLCY6yOPg4oJIx2eRPGxuZyh1SsZE0oPvvsM/Tq1Qs1a9ZEdHQ0vv76a8TFxWHYsGGQJAkTJkyAv78/PDw84OHhAX9/f5ibm2PQoEEGiykxLRGtNrcqlm09THgI763eetU9OegkzPX85YqJidH2TGRNJrLKLzkZP348vvrqK/zxxx+YPHmyXvslIqLC2/rPZDxRSHBWA706fCl3OMVO1oTi3r17GDhwIB4/foxq1aqhdevWOHHiBFxcXAAAkydPRmJiIvz8/PD06VO0atUKe/fuhaVl+RgRW1g3btyAECJbz4KtrS2SkpIAAOPGjcuzJ8fGxgZ2dnZ8PDkRUQl48TwKax6fAhQSxrj2gpGxqdwhFTtZE4qtW7fmuVySJMyePRuzZ88umYCQfunh5KCT+dY78/AM/P7xy7deYJdANLdvrtd+C+rVXohTp05Bo9Fg8ODBSE5Oznf9Vwe4WlhYaN+r1WokJyfrlLVv3x5///03AODw4cN48803tctSUlIghMAvv/yiLZs+fTqmT59e4OMiIipvthyYgmcKCa5qoEf7mXKHYxClagxFaSBJkl6XHrydvGFvbo/ohOgcx1FIkGBvbg9vJ2+9xlAUhLu7OyRJwtWrV3XKa9WqBQAwM8s/OYmJicGjR4/g5uamLQsLC9O+P3nyJKZMmYKgoCBtWdbtenl56dT/v//7P9y/f1+nV8TGpmzPS09EVByex0diTcyZ9LETtXqXy94JgAlFoSkVSkxtORWTgiZBgqSTVEhI/6t/SsspxZ5MAEDVqlXRrVs3LFq0CP/5z39yHUeRlx9//BEKhQK9e/fWlrm7u2vf37t3D0ZGRjplWZmZmekss7GxQVxcXK71iYgqqo0HPkecQoKbWsKb7b6QOxyDKVW3jZY1XV26YkHHBbAzt9Mptze3x4KOC9DVpavB9h0YGIi0tDR4eXlh27ZtuHLlCq5du4aNGzfi6tWrUCpfJjLx8fGIiorC3bt3cejQIYwaNQpff/01vvnmGyYAREQGFBd7F+ufhAEA/Nz7QmlkIm9ABsQeiiLq6tIVnZw74Wz0WTxKeIRq5tXQzK6ZQXomsqpduzZCQ0Ph7++PadOm4d69e1CpVGjQoAE+++wz+Pm9HN8xc+ZMzJw5EyYmJnBwcEDr1q3xzz//oFOnTgaNkYioott4YDLiFRLc1RK6t50hdzgGJYmsExaUQ3FxcbC2tkZsbGy2Sa6SkpIQHh4ONzc3mJqWz2tapRm/fyIqz2Jj7+CNHT3wXCHh+1rvo3v7/8odUoHldQ59FS95EBERGcD6A5/juUJCHY0CXb2nyh2OwTGhICIiKmbPnoZj47NLAAC/OgOhUJb/EQZMKIiIiIrZ2gOfI0Ehob5Gic5tKsZsxEwoiIiIitGTJzewOS59nqCx9T6ApKgYp9qKcZT5KOfjUkstfu9EVB6tPfA5EhUSGmiU6NhqktzhlJgKnVAYGxsDABISEmSOpGLK/N4zfw5ERGXd48dXsSX+XwDAuAYfVpjeCaCCz0OhVCpRuXJlREdHAwDMzc0L9AhxKhwhBBISEhAdHY3KlSvrTMJFRFSWrTk4BUkKCU00Rmjf4j9yh1OiKnRCAQAODg4AoE0qqORUrlxZ+/0TEZV1j6IvYdvzm4BCgl+jERWqdwJgQgFJkuDo6Ag7OzukpqbKHU6FYWxszJ4JIipXVgVNRbJCQlNhDO/m+T+Nuryp8AlFJqVSyRMcEREVysOH5/FzQjggSfBrPKrC9U4AFXxQJhERUXFYGTQVKZKEZsIErT1HyR2OLJhQEBERFUFUZCh+TbwDAPj4Nb8K2TsBMKEgIiIqkhXB05AqSWghVGjhOULucGTDhIKIiKiQ7t8/hR1J9wAAfk0/ljkaeTGhICIiKqQVh/6LNElCa5jBq+lwucORFRMKIiKiQrh79zj+SH4AABjXbLzM0ciPCQUREVEhLD/8BdIkCW1hjqaNB8sdjuyYUBARERXQnTtHsDMlCgDg51VxHgCWFyYUREREBbTsyEyoJQntpUpo0vB9ucMpFZhQEBERFUB4RBD+l5L+/KdxLT6XOZrSgwkFERFRASw7OgcaSUJHyRIN6/eVO5xSgwkFERGRnm6F/4NdqY8AAH6tpsgcTenChIKIiEhPS47OgZAkdFFYoX7dd+QOp1RhQkFERKSHf2/sxp60JwCAsa2nyxxN6cOEgoiISA9Ljn8DIUnopqiMuh495Q6n1GFCQURElI9r1/+HfZpnkITA2DYz5A6nVGJCQURElI8lJwMAAK8b2cDD/Q2ZoymdmFAQERHl4fLV3/GPJi69d6LtLLnDKbWYUBAREeVhyal5AIAextVQy62LzNGUXkwoiIiIcnHpyq8IEvFQCIExbWfLHU6pxoSCiIgoF4tD5gMA3jKxg6urj8zRlG5MKIiIiHJw7uJWHBYvoBQCo9t9KXc4pV6pSSgCAgIgSRImTJigLRNCYPbs2XBycoKZmRk6duyIS5cuyRckERFVGEvO/AAA6GXigJo128kcTelXKhKKkJAQLF++HE2aNNEpnzdvHhYsWIBFixYhJCQEDg4O6NatG+Lj42WKlIiIKoLQ8xtxFAkwEgKj2n8ldzhlguwJxfPnzzF48GCsWLECVapU0ZYLIbBw4ULMmDEDffr0QaNGjbBu3TokJCRg8+bNMkZMRETl3eLQHwEA76ic4OzcRuZoygbZE4px48ahZ8+e6Nq1q055eHg4oqKi0L17d22ZSqWCj48Pjh07luv2kpOTERcXp/MiIiLS1+mwtTiJpPTeCR9/ucMpM4zk3PnWrVtx9uxZhISEZFsWFRUFALC3t9cpt7e3x+3bt3PdZkBAAObMmVO8gRIRUYURGLYIkIA+pjXg5OQldzhlhmw9FHfv3sX48eOxceNGmJqa5lpPkiSdz0KIbGVZTZs2DbGxsdrX3bt3iy1mIiIq306FrkSIlAxjIfCRT4Dc4ZQpsvVQnDlzBtHR0WjevLm2TK1W49ChQ1i0aBGuXbsGIL2nwtHRUVsnOjo6W69FViqVCiqVynCBExFRuSQ0Giw+twSQgL5mNeHg6Cl3SGWKbD0UXbp0wYULFxAWFqZ9eXl5YfDgwQgLC0OtWrXg4OCAffv2addJSUlBcHAwvL295QqbiIjKqROhy3FWSoGJEBjZ8Vu5wylzZOuhsLS0RKNGjXTKKlWqhKpVq2rLJ0yYAH9/f3h4eMDDwwP+/v4wNzfHoEGD5AiZiIjKKaHRIPDCckAC+pu7wd6+Sf4rkQ5ZB2XmZ/LkyUhMTISfnx+ePn2KVq1aYe/evbC0tJQ7NCIiKkeOnQlEmJQKlUbAl70ThSIJIYTcQRhSXFwcrK2tERsbCysrK7nDISKiUkZoNBi8rjkuKNIw1LwWPn/vD7lDKjUKcg6VfR4KIiIiOR0O+QkXFGkw0wh82Gmu3OGUWUwoiIiowhIaDRZfXgMAGGDpAVvbejJHVHYxoSAiogor6OQCXFaoYaYRGN55vtzhlGlMKIiIqEISGg0Cr24AAAy2qgcbG3eZIyrbmFAQEVGFdOD4PFxVaFBJIzCMvRNFxoSCiIgqHI06DYuvbwEADK7cEJWruMkcUdnHhIKIiCqc/ce+xb8KDSw0AkPZO1EsmFAQEVGFok5LQeC/2wEAQyo3hrV1TZkjKh+YUBARUYWy96g/bioFLDUCH3SeJ3c45QYTCiIiqjDUaSlYcnMHAGCoTVNYWTvLHFH5wYSCiIgqjL+PfIVwpYCVRuADjp0oVkwoiIioQkhLTcLSW78DAD6s2hwWlo7yBlTOMKEgIqIKYdfhL3FbCVTWCAzszGd2FDcmFEREVO6lpiZgacROAMCHti1RycJB5ojKHyYURERU7v0veBbuKgEbjcCALryzwxCYUBARUbmWmpqAZXd2AwB87drA3NxW5ojKJyYURERUrv0R9F/cVwJV1QL9O3HshKEwoSAionIrNfkFlt/dCwAY6dgOZuY2MkdUfjGhICKicuu3oOmIVEqophbo1zFA7nDKNSYURERULiUnxWL5/X8AACOdfGBqVkXmiMo3JhRERFQu/Ro0HQ+VEuzVAn07+ssdTrnHhIKIiMqdpMSnWPUgGADwUfXOUJlayxxR+ceEgoiIyp1fgqYhWinBUS3wbsdv5A6nQmBCQURE5UpiwhOsijwCABjl3B0mKkuZI6oYmFAQEVG5sv3gVDxWSqiuBt7p+LXc4VQYTCiIiKjcSEh4jNXRxwAAo2u+AWNjc5kjqjiYUBARUbmx7cAUPFFIcFYDb/nMkTucCoUJBRERlQsvnkdh9aOTAIDRrj3ZO1HCmFAQEVG5sOXAFDxTSHBRAz3bz5Y7nAqHCQUREZV5z+MjsTbmDABgTK3eMDI2lTmiiocJBRERlXmbDkxGrEKCm1rCm+2+kDucCokJBRERlWlxsXex7kkoAGBs7T5QGpnIHFHFxISCiIjKtE0HpyBeIaG2WkL3ttPlDqfCKlBCMW/ePCQmJmo/Hzp0CMnJydrP8fHx8PPzK77oiIiI8hAbewfrn54HAIz1eI+9EzIqUEIxbdo0xMfHaz+/9dZbuH//vvZzQkICli1bVnzRERER5WH9gc/xXCHBQ6NAN+9pcodToRUooRBC5PmZiIiopDx7Go5Nzy4BAPw8BkChNJI5ooqNYyiIiKhMWnfgc7xQSKinUaBzm8/lDqfCY0JBRERlzpMnN7Ap7ioAwK/eEPZOlAIF/gmsXLkSFhYWAIC0tDSsXbsWtra2AKAzvkIfS5YswZIlSxAREQEAaNiwIWbOnIk333wTQPollTlz5mD58uV4+vQpWrVqhcWLF6Nhw4YFDZuIiMqRtQcnI1EhoYFGiY6tJskdDgGQRAEGQri6ukKSpHzrhYeH67W9nTt3QqlUwt3dHQCwbt06zJ8/H6GhoWjYsCHmzp2Lb775BmvXrkWdOnXw9ddf49ChQ7h27RosLfV7vn1cXBysra0RGxsLKysrvdYhIqLS6/Hjq+ixsx8SFRIW1/NFh1YT5Q6p3CrIObRACUVJsLGxwfz58+Hr6wsnJydMmDABU6ZMAQAkJyfD3t4ec+fOxejRo/XaHhMKIqLyZf7P72B9wi001hhh07AzkBS8em8oBTmHlpqfglqtxtatW/HixQu0adMG4eHhiIqKQvfu3bV1VCoVfHx8cOzYsVy3k5ycjLi4OJ0XERGVD4+iL2Hb85sAAL+GvkwmSpEC/SROnjyJv//+W6ds/fr1cHNzg52dHUaNGqUz0ZU+Lly4AAsLC6hUKowZMwa//fYbGjRogKioKACAvb29Tn17e3vtspwEBATA2tpa+3J2di5QPEREVHqtDpqKZIWE1zTGaOs1Tu5wKIsCJRSzZ8/G+fPntZ8vXLiAESNGoGvXrpg6dSp27tyJgICAAgVQt25dhIWF4cSJExg7diyGDRuGy5cva5e/OmZDCJHnOI5p06YhNjZW+7p7926B4iEiotLp4cPz2J6QPkZvXJNR7J0oZQp0l0dYWBi++uor7eetW7eiVatWWLFiBQDA2dkZs2bNwuzZs/XepomJiXZQppeXF0JCQvDjjz9qx01ERUXB0dFRWz86Ojpbr0VWKpUKKpWqIIdFRERlwKqgaUiRJDQTJmjtOUrucOgVBUrvnj59qnMyDw4OxhtvvKH93KJFiyL3CAghkJycDDc3Nzg4OGDfvn3aZSkpKQgODoa3t3eR9kFERGVLVGQofkm8DQAY99pY9k6UQgXqobC3t0d4eDicnZ2RkpKCs2fPYs6cOdrl8fHxMDY21nt706dPx5tvvglnZ2fEx8dj69atCAoKwu7duyFJEiZMmAB/f394eHjAw8MD/v7+MDc3x6BBgwoSNhERlXErg6cjVZLQQqjQ0nOk3OFQDgqUULzxxhuYOnUq5s6di99//x3m5uZo3769dvn58+dRu3Ztvbf38OFDDBkyBJGRkbC2tkaTJk2we/dudOvWDQAwefJkJCYmws/PTzux1d69e/Weg4KIiMq+Bw9O49eku4Akwa/px3KHQ7ko0DwUjx49Qp8+fXD06FFYWFhg7dq16NOnj3Z5ly5d0Lp1a3zzzTcGCbYwOA8FEVHZNntLd/yaEolWMMXKYSFyh1OhFOQcWqAeimrVquHw4cOIjY2FhYUFlEqlzvKff/6ZvQdERFRs7t07gT+SHwCShHGe4+UOh/JQoITC19dXr3qrV68uVDBERERZLT/8X6RJErxhBs8mH8gdDuWhQAnF2rVr4eLiAk9PT5SyGbuJiKicuXPnCP5MjkofO9GcDwAr7QqUUIwZMwZbt27FrVu34Ovriw8++AA2NjaGio2IiCqwZUdmQS1JaC9VwmuNBsgdDuWjQDfyBgYGIjIyElOmTMHOnTvh7OyM/v37Y8+ePeyxICKiYhMREYz/pTwEAPh5fSpzNKSPAs8MolKpMHDgQOzbtw+XL19Gw4YN4efnBxcXFzx//twQMRIRUQWz9OhsaCQJHSVLNGrwntzhkB6KNNWYJEmQJAlCCGg0muKKiYiIKrBb4f/g79RHAAC/VlNkjob0VeCEIjk5GVu2bEG3bt1Qt25dXLhwAYsWLcKdO3dgYWFhiBiJiKgCWXr0S2gkCZ0VVqhf9x25wyE9FWhQpp+fH7Zu3YqaNWviww8/xNatW1G1alVDxUZERBXMjZt7sTstJv3OjlbT5A6HCqBAM2UqFArUrFkTnp6eeT5CfMeOHcUSXHHgTJlERGXHpxvbY6/6GboprLFgyBG5w6nwDDZT5tChQ/NMJIiIiArr2r9/Ya/6GSQhMLbNf+UOhwqowBNbERERGcKSE/4AgNeNbODh/obM0VBB8YHyREQkuyvX/sA/mjhIQmBMmy/kDocKgQkFERHJLvDkXADAm8a2qF27m8zRUGEwoSAiIllduvIrgkQ8FEJgTNvZcodDhcSEgoiIZBUY8h0AoKexHdxcO8obDBUaEwoiIpLN+UvbcEg8h1IIjG43R+5wqAiYUBARkWwCTy8AAPQycYCLS3uZo6GiYEJBRESyCLuwCUeRACMhMKr9V3KHQ0XEhIKIiGSx+OyPAIB3VE5wdm4jczRUVEwoiIioxJ05tw4nkAgjIfBRh6/lDoeKARMKIiIqcYGhPwEA3jWtgerVW8ocDRUHJhRERFSiQkJX4ZSUDGMh8FGHb+QOh4oJEwoiIioxQqPB4nNLAAB9zWrC0am5zBFRcWFCQUREJeZk6AqckZJhIgRGdvxW7nCoGDGhICKiEiE0Giy+sAwA8J65G+ztm8gcERUnJhRERFQijp9ZgjApFSqNwAj2TpQ7TCiIiMjghEaDxRdXAgD6W9RGNbuGMkdExY0JBRERGdzhkJ9wXpEGU42Ab6e5codDBsCEgoiIDEpoNAi8vAYAMNDSA7a29WSOiAyBCQURERlU8KkfcEmhhplGYHjn+XKHQwbChIKIiAxGaDQIvLIBADDIqh5sbNxljogMhQkFEREZzIET83FFoYY5eyfKPSYURERkEBp1GgKvbQYADLZugMpV3GSOiAyJCQURERnE/mPf4rpCAwuNwLDO8+QOhwyMCQURERU7jToNS/7dDgD4oHJjWFd2lTcgMjgmFEREVOz2Hv0GN5QClhqBIeydqBBkTSgCAgLQokULWFpaws7ODr1798a1a9d06gghMHv2bDg5OcHMzAwdO3bEpUuXZIqYiIjyo05LQeCNXwEAQ22awsraWeaIqCTImlAEBwdj3LhxOHHiBPbt24e0tDR0794dL1680NaZN28eFixYgEWLFiEkJAQODg7o1q0b4uPjZYyciIhys/vI1whXClhpBD7gnR0VhiSEEHIHkenRo0ews7NDcHAwOnToACEEnJycMGHCBEyZMgUAkJycDHt7e8ydOxejR4/Od5txcXGwtrZGbGwsrKysDH0IREQVWlpqEt7d0AIRSuCTKp746O31codERVCQc2ipGkMRGxsLALCxsQEAhIeHIyoqCt27d9fWUalU8PHxwbFjx3LcRnJyMuLi4nReRERUMnYd/hIRSqCyRmAQx06UGLVG4PjNGPwRdh/Hb8ZArSn5vgKjEt9jLoQQmDRpEtq1a4dGjRoBAKKiogAA9vb2OnXt7e1x+/btHLcTEBCAOXPmGDZYIiLKJi01CUsjdgJKYLhtC1SycJA7pAph98VIzNl5GZGxSdoyR2tTzOrVAG80ciyxOEpND8XHH3+M8+fPY8uWLdmWSZKk81kIka0s07Rp0xAbG6t93b171yDxEhGRrp2HZuKuErDRCAzkE0VLxO6LkRi78axOMgEAUbFJGLvxLHZfjCyxWEpFQvGf//wHf/75Jw4ePIgaNWpoyx0c0rPbzJ6KTNHR0dl6LTKpVCpYWVnpvIiIyLBSUxOw7PbfAABfuzYwt7CTOaLyT60RmLPzMnK6uJFZNmfn5RK7/CFrQiGEwMcff4wdO3bgwIEDcHPTnZbVzc0NDg4O2Ldvn7YsJSUFwcHB8Pb2LulwiYgoF38GfYH7SqCqWqA/eydKxKnwJ9l6JrISACJjk3Aq/EmJxCPrGIpx48Zh8+bN+OOPP2BpaantibC2toaZmRkkScKECRPg7+8PDw8PeHh4wN/fH+bm5hg0aJCcoRMRUYbU5BdYdncPoJQwwqEtzMxt5A6pQgi981SvetHxuScdxUnWhGLJkiUAgI4dO+qUr1mzBsOHDwcATJ48GYmJifDz88PTp0/RqlUr7N27F5aWliUcLRER5eS34BmIVEqophZ4r9O3codT7p2OeILAoJs4cDVar/p2lqYGjiidrAmFPlNgSJKE2bNnY/bs2YYPiIiICiQlOR7L7+1P751w7ABTsypyh1QuCSFw6N/HWHzwhvYShgRAZaxAUqomx3UkAA7WpmjpVjI9RqXmtlEiIip7fj04DQ+VEuzUAv06BcgdTrmj0QjsuRSFxUE3cPF++rxKxkoJfZvVwGif2rgWFYexG88CgM7gzMz7IGf1agClIue7IosbEwoiIiqU5KRYrHwQBCgljKreGSpTa7lDKjdS1Rr8EfYAS4Ju4Oaj9MdRmBorMKilCz7q4AZHazMAgJttJSz5oFm2eSgcZJiHggkFEREVyi8HpyJaKcFBLfBux2/kDqdcSEpVY/vpu1gWfAv3nyUCACxNjTDc2xXDvV1R1UKVbZ03GjmiWwMHnAp/guj4JNhZpl/mKKmeiUxMKIiIqMCSEp9iZeTh9N6JGt1gouJA+aKIT0rFxhN3sOrILTx+ngIAsLUwwYh2tfBB65qwNDXOc32lQkKb2lVLItRcMaEgIqIC235wCh4rJVRXA719vpY7nDIr5nky1h6LwNpjEYhPSgMAVK9shtE+tdDfyxmmxkqZI9QfEwoiIiqQhITHWPXwGKCQMKrm6zBWVZI7pDInMjYRyw/dwpZTd7R3adSuVgl+Hd3xdlMnGCtLxUTWBcKEgoiICmTbgSl4opBQQw308vlS7nDKlPDHL7A06CZ2hN5Dqjr9vozG1a0xrlNtdG/gAEUJj3soTkwoiIhIbwnPo7Hm0UlAIWGMa08YG5vLHVKZcPlBHAKDbmDXhUhkPlqjlZsNxnVyR3sP21wfeFmWMKEgIiK9bT44GU8VElzUQM/2s+UOp9Q7c/sJFh/UndWycz07+HWsDS/X8jVFORMKIiLSy/P4SKx9fBpQSBjt9g6MjEtmSueyRgiBwxmzWp7MmNVSIQE9GjtibMfaaOhUPufrYEJBRER62XxwMmIVElzVEnq0nyl3OKWORiOw93IUFh+8iQv3YwHozmrpZlu+B68yoSAionzFx93H2phQQCFhbO13oTQykTukUiNVrcGfYQ+wJPgmbkQ/B5DzrJblHRMKIiLK18YDnyNeIaG2WsLrbWfIHU6pkJSqxs+n72JpAWa1LM+YUBARUZ5iY+9gw9Pz6Xd2uPer8L0TL2e1DMfj58kACjarZXnFhIKIiPK04cBkxCskuGsU6N52utzhyObJixSsORqOdcciEFfGZ7U0BCYURESUq9hnEdj47CKgkDDOYwAUyop32oiMTcSKQ+HYcuoOElPVANJntRzb0R3vlNFZLQ2h4v1mEBGR3tYd+BwvFBLqahTo3OZzucMpURGPX2Bp8E38evblrJaNqlvh407uZX5WS0NgQkFERDl6+uQmNsZeARQS/OoOrjC9E1ci4xAYdBN/nX9Qbme1NISK8dtBREQFtubg50hUSKivUaJT68/kDsfgztx+isCDN/BPBZjV0hCYUBARUTYxj69ja9z19LET9YdCUpTPcQKZs1oGBt3AiVvps1pKEtCznM9qaQhMKIiIKJs1BycjUSGhkcYIHVpOkDucYpfbrJZ9PGtgtE8t1KpmIXOEZQ8TCiIi0vH40RVse34jvXeioW+56p3IbVbLgS1r4qP2teBUuWLMamkITCiIiEjHqqApSFJIaKIxRluvcXKHUyxym9VyWBtXfNi24s1qaQhMKIiISCv64UVsf3ELkCSMazyyzPdOxCelYtPJO1h5WHdWS992bvigtQusKuislobAhIKIiLRWBU9FiiShmTBBm2Zj5A6n0J68SMHao+FYy1ktSwwTCiIiAgBERYXh54QIQJLg12R0meydiIpNworDt7D55MtZLWtVqwQ/zmppcEwoiIgIALAyaBpSJQleQoWWTUfKHU6BRDx+gWWHbuKXM7qzWo7r6I7uDR2g5KyWBseEgoiIEPngDH5NupveO9HUr8z0TlyJjMOSoJv4X5ZZLVtmzGrZgbNaligmFEREhOWHpiNNktAKpmjR1FfucPKV06yWnepWg18nd7TgrJayYEJBRFTB3bt3Ar8n3c/onfiP3OHkSgiBIzceY/FB3VktezR2hB9ntZQdEwoiogpuxeEvkCZJ8IYZmr02VO5wskmf1fIhAoNu4Pw9zmpZWjGhICKqwO7ePYo/kiPTeyeaT5I7HB2pag12nnuAwCDOalkWMKEgIqrAlh6eCbUkoR0q4bVGA+QOB0DGrJZn7mFZ8E3ce8pZLcsKJhRERBXU7duH8b+Uh+m9E16fyh0OnienYdOJ21iRZVbLqpVMMKI9Z7UsC5hQEBFVUEuPzIRGkuAjWaBxw/dkiyO3WS1HdUif1dLMhLNalgVMKIiIKqBb4QewK/VReu9EyymyxMBZLcsXJhRERBXQ0qNzoJEkdJKs0KBe7xLdd+aslr+euY8UtQYAZ7UsD5hQEBFVMDdu7sXutJj03olWJdc7cTUqDoEHOatleSVrf9KhQ4fQq1cvODk5QZIk/P777zrLhRCYPXs2nJycYGZmho4dO+LSpUvyBEtEVE4sOf4VhCShm8Ia9eq+bfD9nb3zFCPXheCNhYfx57n0ZKJT3Wr4eUwbbB/dBj51qjGZKAdk7aF48eIFXnvtNXz44Yfo27dvtuXz5s3DggULsHbtWtSpUwdff/01unXrhmvXrsHS0lKGiImIyrbrN/7GXvUzAMCYNjMMth8hBI7eiMHigzdw/FYMAM5qWd7JmlC8+eabePPNN3NcJoTAwoULMWPGDPTp0wcAsG7dOtjb22Pz5s0YPXp0SYZKRFQuLDn+DQDgdWUV1HHPuf0tisxZLZcE3cC5LLNavutZHWN8anNWy3Ks1I6hCA8PR1RUFLp3764tU6lU8PHxwbFjx3JNKJKTk5GcnKz9HBcXZ/BYiYjKgqvX/sR+TSwkITC2zRfFuu00tQZ/nnuAJUE38S9ntayQSm1CERUVBQCwt7fXKbe3t8ft27dzXS8gIABz5swxaGxERGVR4Mm5AIA3jKqidu1uxbLNpFQ1fjlzD0s5q2WFV2oTikyvDtQRQuQ5eGfatGmYNOnlfPRxcXFwdnY2WHxERGXBpas7cFDEQSEExrSdVeTtZc5qufJIOB7Fc1ZLKsUJhYODA4D0ngpHR0dteXR0dLZei6xUKhVUKmbERERZBZ6aDwDoaWyHWm6dC72dpy9SsOZYBNYdi0BsYioAwMnaFKN9anNWywqu1CYUbm5ucHBwwL59++Dp6QkASElJQXBwMObOnStzdEREZceFSz/jkHgOpRAY3a5wl4SjYpOw8vAtbD51BwkpL2e1HOtTG+80rQ4TI85qWdHJmlA8f/4cN27c0H4ODw9HWFgYbGxsULNmTUyYMAH+/v7w8PCAh4cH/P39YW5ujkGDBskYNRFR2bL49HcAgLdMHODi0r5A696OeYGlwbfw65l72lktGzpZYVwnd7zOWS0pC1kTitOnT6NTp07az5ljH4YNG4a1a9di8uTJSExMhJ+fH54+fYpWrVph7969nIOCiEhPYRc34ygS0nsn2n+l93pXo+KwJOgmdp7LMqulqw38OtXmRFSUI0kIIeQOwpDi4uJgbW2N2NhYWFlZyR0OEVGJGrWuJY4jEX1MHDBn4L5865+98xSBB29i/5WH2rJOdavBr5M7WrjaGDJUKoUKcg4ttWMoiIioaM6eW4/jSISREBjV4Ztc62XOahkYdAPHburOajnWpzYaVeeslpQ/JhREROVUYNhPAIB3TWugevWW2ZZrNAL7rjxE4MGXs1oaKST0aVYdo31qozZntaQCYEJBRFQOhYSuwkkkwUgIfPRK70SaWoOd5x8g8KDurJYDWtTERx1qoTpntaRCYEJBRFTOCI0Gi88tASSgr1lNODo1B/ByVstlh27i7pOMWS1VRhjq7YIP27rBlrNaUhEwoSAiKmdOha3EGSkZJkJgpI8/nienYfPJ21hxWHdWS992bhjShrNaUvFgQkFEVI4IjQaLzy8DJOBdUxdsuWCOtccO6MxqOapDLbzfoiZntaRixYSCiKgcOX5mCUKlFKg0AnuuvY27if8CAGrZVsLYjpzVkgyHCQURUTkR8SgeP4QtB0yABrG2OJRYg7NaUolhQkFEVMZlzmp59+ZK/FtDA5VGQDIZi7UftuCsllRimFAQEZVRoXeeYrF2VksNmrgdAgD0MnHDrA/flzc4qnCYUBARlTJqjcCp8CeIjk+CnaUpWrrZaC9XCCFw7GYMFh/UndWyf+3D2GUMmGkEPn79eznDpwqKCQURUSmy+2Ik5uy8jMjYJG2Zo7UpvujZAEZKCYuDbuLc3WcAXs5qOaq9G6bvmgEAGGhVF1Vt68gROlVwTCiIiEqJ3RcjMXbjWbz6xMbI2CT4bT6r/fzqrJb/HJuLKwo1zDUCwzvNK9mgiTIwoSAiKgXUGoE5Oy9nSyaykgCM6VgLI9rV0s5qqVGnYcm1zYACGGxdH1VsapdIvESvYkJBRFTCNBqBx8+T8SA2CZHPEvEgNglnbz/RucyREwGgg4edzhTZ/xyfh2sKDSppBIZ1nm/gyIlyx4SCiKgYCSEQ8yIFkc+S8CA2EZHPEhEZl4TIZ0mIjE3Eg2dJeBiXhDRNXn0RuYuOf5l0aNRpCPx3G6AAhlRuDOvKrsV0FEQFx4SCiEhPQgg8S0jNSBTSE4TI2CRExibhwbP091GxSUhRa/LdlkIC7K1M4WBtCidrMwghsOtiVL7r2Vmaat/vPeqPGwoNLDUCQzpz7ATJiwkFERHSk4W4pLT0JCGjdyEqNgkPdBKHRCSl5p8sSBJQzUIFR2tTOFqbwbFyetLgWNlUW2ZnqYKR8uUU2GqNQOjcA4iKTcpxHIUEwME6/RZSAFCnpWDJjV8AJTCkymuwsnYupm+CqHCYUBBRhfA8OU07XiHz36iMRCGzdyEhRa3XtmwtTOBobZbRu2AKx8pmL5MHa1PYW5kW+HkZSoWEWb0aYOzGs5AAnaQic57LWb0aaOej2H3ka9xSClhpBD5g7wSVAkwoiKjMS0xRay9DZP4bFZf4snfhWRLik9P02lYVc2NtYpDeo2AGp8q6yYKpsWGe0vlGI0cs+aBZtnkoHKxNMatXA7zRyBEAkJaahKW3fgOUwLCqnrC0qm6QeIgKggkFEZVqSanq9EsPeYxbyHw0d36sTI3glNGb4GBtpu1dcLJOH8vgaG0m+yO932jkiG4NHHKdKRMA/j7yFSKUgLVGYDDv7KBSggkFEckmJU2Dh3EvE4Ocxi08eZGi17YsVEYZvQpmcLQyzXHcQiVV2WjylAoJbWpXzXFZWmoSlob/CSiBD21boJKFQwlHR5SzsvG/i4jKnFS1BtHxyTrjFjIHNkZmJA2PnyfrtS0zY6U2QXh13IJT5fQyK1NjAx9R6fC/Q7NwRwlU0QgM7DRX7nCItJhQEFGBqTUCj+KTc7gM8XLcwqP4ZOgz1YKJkSI9QXilNyHruAVrM2M+ghtAamoClt7eBSgB32qtYW5hJ3dIRFpMKIhIh0Yj8PhFss5ETFnHLUQ+S8TD+GSo9cgWjJWSdmyCU+a4hSyJgqO1KWwqmTBZ0NPO4Jm4rwSqqgXe550dVMowoSCqQIQQePIiRWdAY+a4hcw7JB7GJSFVnX+yoFRIcLAyfTluwTp770LVSiZQKJgsFIfU5BdYdmdPeu+EgzfMzG3kDolIBxMKIgNTa0SeI/aLS+YsjtpLDxm9Cdo7JDJ6GFLS9JvF0c4yy8DGjLsgnLKMW7C1UBnkOChnvwXPwAMlYKsW6M+xE1QKMaEgMqDdFyOzzSng+MqcAvrInMUx59snMz8nITE1/4mZJAmwtVDlOW7h1VkcSV4pyfFYcW8/oJQw0rEDTM2qyB0SUTZMKIgMZPfFSIzdeDbbNMpRsUkYu/EslnzQTJtUPE9OQ1SW8QoPniXp9iw8S8QLPWdxrFrJ5OWETDmMWyjMLI4krx0HpyNKKcFOLdCvU4Dc4RDliAlFAZVU9zWVLUIIpGkEUtI0SFVrkJiqxhd/XMrxmQyZZeO3hsHF5joi45IQn6TfLI6VM2ZxdMoyi2PW3gVDzuJI8khOisWKBwcBpYSPnDpBZWotd0hEOWJCUQDF1X1NBafWCKSqNUhRa7Qn7dQ0gRS1GilpL5elpmX8q355ctdZJ+N9ilpo378sF9ptvLpeSsb+sm9PZGwv/3EJr0pO0+B69HPtZytToyyXIF7O3uiU5TkRcs/iSCXvl4PTEK2U4KAW6NPJX+5wiHLFhEJPBem+LmuEEOknxiwn0+QcTpjZTsBZTtovT9QvT/Q662bZXvIr67zcVvo6OtvKWEefWxTLorE+tdG3eXU4WJvBoozM4kiGp05LwdkLG/Dg6b8IjAwGlAp8VKMrTFSWcodGlCu2YHpQawTm7Lyca/e1BGDOzsvo1sAh2+UPIUTGX9cil7+U8/5rOjVNIDnrX81p+ZzM80wCci8va0yUChgrJRgbKTLeK2CS+d5IgnFGmcpIkfFegomRMv3fjLrGOutJr3xO346JUqndj0qpgHHGeunbkLT1tetmfD4V/gQDV5wAACiQhoaVDsHc6DES0mxx6UUHaDL+63WoUw3udjxJ0Ev7jwTg2+ub8FCZ0ZYoFVAIAStTDsSk0o0JhR5OhT/RXubI7eQQGZuE1gH7oZQUOl3vKWoNRBk7XysVUq4n3vSTppTDCTnzpK3I4WSeeXLOug1FRjKQ27Zebs/klf0bK6VSPxFSSzcbOFqboobYgsf2xxGRZRCkS9pu2D5sg3vSQLR041wC9NL+IwGYdGMTxCtjZjUAJt/6GUYKE3RtN02W2Ijyw4RCD9Hx6cmEl9VviMnh5FD1YRucjnsXj+L1e4hR1hPwqyfR9JNmbuXpfxVrT7hGWU/c0isnfd0TsO6J+tW/whU6f+lzkGnRKRUSPmxwAIuenoCA7vcZo5QQ43QCH1exh1LRRaYIqaQIjQZCaKDRpEFo1BDIeC8EhCYt47MaqWmJ8L+ekUy8mjBLEiAE5l7fhE6tP4XSyESWYyHKCxMKPdhZmsLL6jdcd8r95OAF4O1O/0WzmlWynPwV2f7SN1KU/r+uy5PMxlwIDTQio0EX6Q141sZcI9RAZjnEy8ZfiJfrZZaLjPKMMiHU6e+FBhqhhtCooVanYlPMHzmeHETGyWFTzB9ocroGICnSt6NRQyM02m2m71uTEVv6+/R9aABkLtOkn5iEJv1YRObxiizbyviMjGXI3Ba029PWg4BGCO3nzPcv95m+nfR4MpZBpH/O3C6QsS283DYENAIZ2325nu57ZHuf4zK83I4GSN9/xr8v10v/nDlUVqMtQ0asGe8z6mQuy9z2y/cZy6Qs75Hz+xzrFfT/ujL3+kKSEKUEzl7YgBaeIwq2XaISwIRCD82dLRBjfzw9mcjl5BDpcBzWicsRfl3KaMzVOo23RmQ2wlkadGQ2/OKVhj7vhl3bWCPzZJLZ0IpXTiS65ZnbzGjyte9zatR1TgDIPFm8bLi1jbh42XhrG+NXGvVsjbQQOTbeuTXo6Q1zLg04dBvzlycQQCN34pbHyQGShCdK4KNLgSUXT3mT09dbLD/y0p3wP4q7I3cIRDkqEwlFYGAg5s+fj8jISDRs2BALFy5E+/btS2z/5y5txOO8JgKSJMQpJfz37s4Si6nUMEijLn+DLon0vigF0qORAChElvfI5X1GnWRJIE6R/+RR9moBS0kJhXY7UpbtStrPCimzXHq5Tyn908v1pFfqSVBIuSyTJCgyyoD095IEKJAes0JSQJGRQCuy1JckRUY86f+mf87Ydub7jPo5Lsv4V5IUGeUZa0gSFBn/pi97WR9S+r8KSZkeq5RRX1JoPysk5ct9Zq6fUabdp0KZvk2FMiOezHoKSIqMbUABhSJzn0rteunbV0ChyIxBmbEdKWM/Cm2drPUlSfly29r9G6WvpzDK2J8SCskIpy9swKhLi/P9nalmVVOP32CiklfqE4pt27ZhwoQJCAwMRNu2bbFs2TK8+eabuHz5MmrWLJn/WPr+ReChkVBNYZql8ZZenhSkzBMEXjbOWRtqnUY794ZdtyGHtnF92ZC/bJy1JwtJod2mTsOeWZ7RuObVqGu3m9lQZmnYtY0ppJeNZ2ZDnlH+8sSQ0RAjvSHO2qCnN/BKnQZdISl13kuKLNtUKF+eNBRGWeoapTf8GeW6ddMb8FcbcyjS15OyxFMUIaGr4Ht+Yb71AjwnsvuaAAAtm/rC/vwiRCtyvlQiCQF7DdCs8RAZoiPKX6lPKBYsWIARI0Zg5MiRAICFCxdiz549WLJkCQICSmYKWn3/IpjWdDxPDgQgvdG3D/2BJwfSm9LIBFPrDMakG5sgCaHzeyNlXG6cUmcwB2RSqVWqJ/RPSUnBmTNn0L17d53y7t2749ixYzmuk5ycjLi4OJ1XUTVrPAT2aqH9T/0qSQg4qAVPDqSVeXIAkO33hicHyk3XdtOwwH0w7F6ZeNVeAyxwH8xbRqlUK9U9FI8fP4ZarYa9vb1Oub29PaKionJcJyAgAHPmzCnWOPiXAxVG13bTsADImKToZbm9Jv33hScHyknXdtPQqfWnOHthAx7F3UE1q5po1ngI2xcq9Up1QpHp1dsshRC53no5bdo0TJo0Sfs5Li4Ozs7ORY6BJwcqDJ4cqDCURia8fEplTqlOKGxtbaFUKrP1RkRHR2frtcikUqmgUqkMEg9PDlQYPDkQUUVQqhMKExMTNG/eHPv27cO7776rLd+3bx/eeecdWWLiyYGIiCi7Up1QAMCkSZMwZMgQeHl5oU2bNli+fDnu3LmDMWPGyB0aERERZSj1CcX777+PmJgYfPnll4iMjESjRo2wa9cuuLi4yB0aERERZZCEKGvPwiyYuLg4WFtbIzY2FlZWVnKHQ0REVGYU5BxaquehICIiorKBCQUREREVGRMKIiIiKrJSPyizqDKHiBTHFNxEREQVSea5U5/hluU+oYiPjweAYpktk4iIqCKKj4+HtbV1nnXK/V0eGo0GDx48gKWlZa7TdZd2mdOH3717t9zeqVLej5HHV/aV92Ms78cHlP9jNMTxCSEQHx8PJycnKBR5j5Io9z0UCoUCNWrUkDuMYmFlZVUu/xNkVd6PkcdX9pX3YyzvxweU/2Ms7uPLr2ciEwdlEhERUZExoSAiIqIiY0JRBqhUKsyaNctgT1EtDcr7MfL4yr7yfozl/fiA8n+Mch9fuR+USURERIbHHgoiIiIqMiYUREREVGRMKIiIiKjImFAQERFRkTGhKCUCAwPh5uYGU1NTNG/eHIcPH86zfnJyMmbMmAEXFxeoVCrUrl0bq1evLqFoC6egx7hp0ya89tprMDc3h6OjIz788EPExMSUULQFc+jQIfTq1QtOTk6QJAm///57vusEBwejefPmMDU1Ra1atbB06VLDB1pIBT2+HTt2oFu3bqhWrRqsrKzQpk0b7Nmzp2SCLYTC/PwyHT16FEZGRmjatKnB4isOhTnGstTOFOb4ylIbExAQgBYtWsDS0hJ2dnbo3bs3rl27lu96JdnOMKEoBbZt24YJEyZgxowZCA0NRfv27fHmm2/izp07ua7Tv39//PPPP1i1ahWuXbuGLVu2oF69eiUYdcEU9BiPHDmCoUOHYsSIEbh06RJ+/vlnhISEYOTIkSUcuX5evHiB1157DYsWLdKrfnh4OHr06IH27dsjNDQU06dPxyeffIJff/3VwJEWTkGP79ChQ+jWrRt27dqFM2fOoFOnTujVqxdCQ0MNHGnhFPT4MsXGxmLo0KHo0qWLgSIrPoU5xrLUzhT0+MpaGxMcHIxx48bhxIkT2LdvH9LS0tC9e3e8ePEi13VKvJ0RJLuWLVuKMWPG6JTVq1dPTJ06Ncf6f//9t7C2thYxMTElEV6xKOgxzp8/X9SqVUun7P/+7/9EjRo1DBZjcQEgfvvttzzrTJ48WdSrV0+nbPTo0aJ169YGjKx46HN8OWnQoIGYM2dO8QdUzApyfO+//77473//K2bNmiVee+01g8ZVnPQ5xrLYzmTS5/jKchsjhBDR0dECgAgODs61Tkm3M+yhkFlKSgrOnDmD7t2765R3794dx44dy3GdP//8E15eXpg3bx6qV6+OOnXq4LPPPkNiYmJJhFxghTlGb29v3Lt3D7t27YIQAg8fPsQvv/yCnj17lkTIBnf8+PFs38frr7+O06dPIzU1VaaoDEej0SA+Ph42NjZyh1Js1qxZg5s3b2LWrFlyh2IQZa2dKaiy3sbExsYCQJ7/p0q6nSn3Dwcr7R4/fgy1Wg17e3udcnt7e0RFReW4zq1bt3DkyBGYmprit99+w+PHj+Hn54cnT56UyuubhTlGb29vbNq0Ce+//z6SkpKQlpaGt99+Gz/99FNJhGxwUVFROX4faWlpePz4MRwdHWWKzDC+//57vHjxAv3795c7lGLx77//YurUqTh8+DCMjMpnM1rW2pmCKsttjBACkyZNQrt27dCoUaNc65V0O8MeilLi1UerCyFyfdy6RqOBJEnYtGkTWrZsiR49emDBggVYu3Ztqf7roSDHePnyZXzyySeYOXMmzpw5g927dyM8PBxjxowpiVBLRE7fR07lZd2WLVswe/ZsbNu2DXZ2dnKHU2RqtRqDBg3CnDlzUKdOHbnDMZiy2s7oqyy3MR9//DHOnz+PLVu25Fu3JNuZ8plalyG2trZQKpXZ/lKPjo7OlllmcnR0RPXq1XUeKVu/fn0IIXDv3j14eHgYNOaCKswxBgQEoG3btvj8888BAE2aNEGlSpXQvn17fP3112X+L3gHB4ccvw8jIyNUrVpVpqiK37Zt2zBixAj8/PPP6Nq1q9zhFIv4+HicPn0aoaGh+PjjjwGkn3yFEDAyMsLevXvRuXNnmaMsurLWzhRUWW1j/vOf/+DPP//EoUOHUKNGjTzrlnQ7wx4KmZmYmKB58+bYt2+fTvm+ffvg7e2d4zpt27bFgwcP8Pz5c23Z9evXoVAo8v0Fk0NhjjEhIQEKhe6vp1KpBPAywy7L2rRpk+372Lt3L7y8vGBsbCxTVMVry5YtGD58ODZv3lxmrkvrw8rKChcuXEBYWJj2NWbMGNStWxdhYWFo1aqV3CEWi7LWzhRUWWtjhBD4+OOPsWPHDhw4cABubm75rlPi7YxBhnpSgWzdulUYGxuLVatWicuXL4sJEyaISpUqiYiICCGEEFOnThVDhgzR1o+Pjxc1atQQ/fr1E5cuXRLBwcHCw8NDjBw5Uq5DyFdBj3HNmjXCyMhIBAYGips3b4ojR44ILy8v0bJlS7kOIU/x8fEiNDRUhIaGCgBiwYIFIjQ0VNy+fVsIkf34bt26JczNzcXEiRPF5cuXxapVq4SxsbH45Zdf5DqEPBX0+DZv3iyMjIzE4sWLRWRkpPb17NkzuQ4hTwU9vleVhbs8CnqMZa2dKejxlbU2ZuzYscLa2loEBQXp/J9KSEjQ1pG7nWFCUUosXrxYuLi4CBMTE9GsWTOdW4GGDRsmfHx8dOpfuXJFdO3aVZiZmYkaNWqISZMm6fxilUYFPcb/+7//Ew0aNBBmZmbC0dFRDB48WNy7d6+Eo9bPwYMHBYBsr2HDhgkhcj6+oKAg4enpKUxMTISrq6tYsmRJyQeup4Ien4+PT571S5vC/PyyKgsJRWGOsSy1M4U5vrLUxuR0bADEmjVrtHXkbmf4+HIiIiIqMo6hICIioiJjQkFERERFxoSCiIiIiowJBRERERUZEwoiIiIqMiYUREREVGRMKIiIiKjImFAQERFRkTGhICqlIiIiIEkSwsLC9F5n7dq1qFy5skHiSUlJgbu7O44ePVro+EjXokWL8Pbbb8sdBlGxYEJBRHpZvnw5XFxc0LZtWwCAs7MzIiMj0ahRoxKPxdXVFQsXLizx/Ra3jz76CCEhIThy5IjcoRAVGRMKItLLTz/9hJEjR2o/K5VKODg4wMjISMaoCiY1NVXuEHSoVCoMGjQIP/30k9yhEBUZEwoimezevRvt2rVD5cqVUbVqVbz11lu4efNmrvWDgoIgSRL++usvvPbaazA1NUWrVq1w4cKFbHX37NmD+vXrw8LCAm+88QYiIyO1y0JCQtCtWzfY2trC2toaPj4+OHv2bJ6xnj17Fjdu3NB5DPmrlzwy4/vnn3/g5eUFc3NzeHt749q1a9p1Zs+ejaZNm2LZsmVwdnaGubk53nvvPTx79kxbp2PHjpgwYYLO/nv37o3hw4drl9++fRsTJ06EJEmQJCnXuCVJwtKlS/HOO++gUqVK+Prrr6FWqzFixAi4ubnBzMwMdevWxY8//qiz3vDhw9G7d2989913cHR0RNWqVTFu3DidhCQyMhI9e/aEmZkZ3NzcsHnz5mw9J7GxsRg1ahTs7OxgZWWFzp0749y5czr7evvtt/H7778jMTExrx8BUanHhIJIJi9evMCkSZMQEhKCf/75BwqFAu+++y40Gk2e633++ef47rvvEBISAjs7O7z99ts6J7qEhAR899132LBhAw4dOoQ7d+7gs88+0y6Pj4/HsGHDcPjwYZw4cQIeHh7o0aMH4uPjc93noUOHUKdOHVhZWeV7XDNmzMD333+P06dPw8jICL6+vjrLb9y4ge3bt2Pnzp3YvXs3wsLCMG7cuHy3m2nHjh2oUaMGvvzyS0RGRuokSzmZNWsW3nnnHVy4cAG+vr7QaDSoUaMGtm/fjsuXL2PmzJmYPn06tm/frrPewYMHcfPmTRw8eBDr1q3D2rVrsXbtWu3yoUOH4sGDBwgKCsKvv/6K5cuXIzo6WrtcCIGePXsiKioKu3btwpkzZ9CsWTN06dIFT5480dbz8vJCamoqTp06pfd3QFQqGew5pkRUINHR0QKAuHDhghBCiPDwcAFAhIaGCiFePp5569at2nViYmKEmZmZ2LZtmxBCiDVr1ggA4saNG9o6ixcvFvb29rnuNy0tTVhaWoqdO3fmWmf8+PGic+fOOmW5xbd//35tnb/++ksAEImJiUKI9Md8K5VKcffuXW2dv//+WygUChEZGSmESH/0+fjx43X29c477+g8+tzFxUX88MMPucabCYCYMGFCvvX8/PxE3759tZ+HDRsmXFxcRFpamrbsvffeE++//74QIv2x3gBESEiIdvm///4rAGjj+ueff4SVlZVISkrS2Vft2rXFsmXLdMqqVKki1q5dm2+cRKUZeyiIZHLz5k0MGjQItWrVgpWVFdzc3AAAd+7cyXO9Nm3aaN/b2Nigbt26uHLlirbM3NwctWvX1n52dHTU+cs5OjoaY8aMQZ06dWBtbQ1ra2s8f/48z/0mJibC1NRUr+Nq0qSJzr4z95mpZs2aqFGjhs7xaDQanUsjxcnLyytb2dKlS+Hl5YVq1arBwsICK1asyHb8DRs2hFKp1H7O+j1eu3YNRkZGaNasmXa5u7s7qlSpov185swZPH/+HFWrVoWFhYX2FR4enu3SlpmZGRISEorleInkUnZGUxGVM7169YKzszNWrFgBJycnaDQaNGrUCCkpKQXeVtZxBMbGxtmWCSG0n4cPH45Hjx5h4cKFcHFxgUqlQps2bfLcr62tbY5jNXKSdf+ZceV1GSezTua/CoVCJ16gaIMpK1WqpPN5+/btmDhxIr7//nu0adMGlpaWmD9/Pk6ePJnrcWTGl3kcr8aXKWu5RqOBo6MjgoKCstV79dbeJ0+eoFq1avoeElGpxISCSAYxMTG4cuUKli1bhvbt2wOA3rcOnjhxAjVr1gQAPH36FNevX0e9evX03vfhw4cRGBiIHj16AADu3r2Lx48f57mOp6cnlixZAiFEnoMg9XHnzh08ePAATk5OAIDjx49DoVCgTp06AIBq1arpjItQq9W4ePEiOnXqpC0zMTGBWq0u1P4PHz4Mb29v+Pn5acvyGgybk3r16iEtLQ2hoaFo3rw5gPSxIVkHlzZr1gxRUVEwMjKCq6trrtu6efMmkpKS4OnpWaAYiEobXvIgkkGVKlVQtWpVLF++HDdu3MCBAwcwadIkvdb98ssv8c8//+DixYsYPnw4bG1t0bt3b7337e7ujg0bNuDKlSs4efIkBg8eDDMzszzX6dSpE168eIFLly7pvZ/cmJqaYtiwYTh37hwOHz6MTz75BP3794eDgwMAoHPnzvjrr7/w119/4erVq/Dz89M5UQPp81AcOnQI9+/fzzcZepW7uztOnz6NPXv24Pr16/jiiy8QEhJSoG3Uq1cPXbt2xahRo3Dq1CmEhoZi1KhRMDMz0yZcXbt2RZs2bdC7d2/s2bMHEREROHbsGP773//i9OnT2m0dPnwYtWrV0rlMRVQWMaEgkoFCocDWrVtx5swZNGrUCBMnTsT8+fP1Wvfbb7/F+PHj0bx5c0RGRuLPP/+EiYmJ3vtevXo1nj59Ck9PTwwZMgSffPIJ7Ozs8lynatWq6NOnDzZt2qT3fnLj7u6OPn36oEePHujevTsaNWqEwMBA7XJfX18MGzYMQ4cOhY+PD9zc3HR6J4D0pCoiIgK1a9cu8KWCMWPGoE+fPnj//ffRqlUrxMTE6PRW6Gv9+vWwt7dHhw4d8O677+Kjjz6CpaWldqyJJEnYtWsXOnToAF9fX9SpUwcDBgxAREQE7O3ttdvZsmULPvroowLvn6i0kURuFwOJqFQJCgpCp06d8PTpU4NNr52XCxcuoGvXrrhx4wYsLS0LtY3Zs2fj999/L5fTdd+7dw/Ozs7Yv38/unTpotc6Fy9eRJcuXXD9+nVYW1sbOEIiw+IYCiLSS+PGjTFv3jxERESgcePGcocjuwMHDuD58+do3LgxIiMjMXnyZLi6uqJDhw56b+PBgwdYv349kwkqF5hQEJHehg0bJncIpUZqaiqmT5+OW7duwdLSEt7e3ti0aVO2u0Py0r17dwNGSFSyeMmDiIiIioyDMomIiKjImFAQERFRkTGhICIioiJjQkFERERFxoSCiIiIiowJBRERERUZEwoiIiIqMiYUREREVGT/D/pymduu1lssAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "alphas = [0.5, 1.0, 1.5, 2.0]\n",
    "alpha_results = []\n",
    "for a in alphas:\n",
    "    res_a = eval_linear_suite(\n",
    "        n_tasks=10, d=10, N=10, alpha=a,\n",
    "        eta_gd=tune[\"eta\"], use_gdpp=True, gamma=tune[\"gamma\"],\n",
    "        temperature=0.0, do_sensitivity=False\n",
    "    )\n",
    "    res_a[\"alpha\"] = a\n",
    "    alpha_results.append(res_a)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(alphas, [r[\"MSE_llama\"] for r in alpha_results], marker=\"o\", label=\"LLaMA\")\n",
    "plt.plot(alphas, [r[\"MSE_gd1\"] for r in alpha_results], marker=\"o\", label=\"GD-1\")\n",
    "plt.plot(alphas, [r[\"MSE_gdpp\"] for r in alpha_results], marker=\"o\", label=\"GD++\")\n",
    "plt.xlabel(\"alpha (input range)\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"OOD Scaling: MSE vs alpha\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f81b4",
   "metadata": {},
   "source": [
    "\n",
    "## 7.Nonlinear sine tasks (Expected to show large error)\n",
    "We can also test whether the model behaves sensibly on smooth nonlinear targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c80b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sine task results: {'MSE_llama': 499287.75745792844, 'failures': 0, 'evaluated': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class SineTask:\n",
    "    A: float\n",
    "    B: float\n",
    "    C: float\n",
    "    X: np.ndarray      # (N, 1)\n",
    "    y: np.ndarray      # (N, )\n",
    "    x_test: float\n",
    "    y_test: float\n",
    "\n",
    "def sample_sine_task(N: int = 10, alpha: float = 1.0) -> SineTask:\n",
    "    A = np.random.uniform(0.5, 1.5)\n",
    "    B = np.random.uniform(0.5, 2.0)\n",
    "    C = np.random.uniform(0.0, np.pi)\n",
    "    X = np.random.uniform(-alpha, alpha, size=(N, 1))\n",
    "    y = A * np.sin(B * X.reshape(-1) + C)\n",
    "    x_test = float(np.random.uniform(-alpha, alpha))\n",
    "    y_test = float(A * np.sin(B * x_test + C))\n",
    "    return SineTask(A=A, B=B, C=C, X=X, y=y, x_test=x_test, y_test=y_test)\n",
    "\n",
    "def build_prompt_sine(task: SineTask) -> str:\n",
    "    lines = [f\"({task.X[i,0]:.6f}) -> {task.y[i]:.6f}\" for i in range(task.X.shape[0])]\n",
    "    ctx = \"\\n\".join(lines)\n",
    "    prompt = (\n",
    "        \"You are solving a noiseless regression task where y is a smooth function of x.\\n\"\n",
    "        \"Given training pairs (x -> y), predict y for the query x_test.\\n\\n\"\n",
    "        + ctx + \"\\n\\n\"\n",
    "        + f\"x_test = {task.x_test:.6f}\\n\"\n",
    "        + \"Return only a single number (or JSON {\\\"y\\\": <number>}).\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def eval_sine_suite(n_tasks: int = 10, N: int = 10, alpha: float = 1.0, temperature: float = 0.0):\n",
    "    gt_list, llama_list = [], []\n",
    "    fails = 0\n",
    "    for _ in range(n_tasks):\n",
    "        t = sample_sine_task(N=N, alpha=alpha)\n",
    "        p = build_prompt_sine(t)\n",
    "        _, pred = llama_predict(p, temperature=temperature)\n",
    "        if pred is None or not np.isfinite(pred):\n",
    "            fails += 1\n",
    "            continue\n",
    "        gt_list.append(t.y_test); llama_list.append(pred)\n",
    "    return {\n",
    "        \"MSE_llama\": mse(llama_list, gt_list) if llama_list else float(\"nan\"),\n",
    "        \"failures\": fails,\n",
    "        \"evaluated\": len(gt_list)\n",
    "    }\n",
    "\n",
    "sine_res = eval_sine_suite(n_tasks=10, N=10, alpha=1.0, temperature=0.0)\n",
    "print(\"Sine task results:\", sine_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5985b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1cbcf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import additional required packages\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class GaussianMixtureDataset(Dataset):\n",
    "    \"\"\"Dataset class for generating Gaussian mixture data\"\"\"\n",
    "    def __init__(self, d: int, N: int, B: int, R: float, is_validation: bool=False, label_flip_p: float =0.0):\n",
    "        self.d = d\n",
    "        self.N = N \n",
    "        self.B = B\n",
    "        self.R = R\n",
    "        self.is_validation = is_validation\n",
    "        self.label_flip_p = label_flip_p\n",
    "        assert 0 <= label_flip_p < 0.5, f'label flip probab must be in [0,1/2), got {label_flip_p}'\n",
    "\n",
    "        if is_validation:\n",
    "            # use different seed for validation data\n",
    "            torch.manual_seed(42)\n",
    "        \n",
    "        # Generate all data at once and store in tensors\n",
    "        self.context_x, self.context_y, self.target_x, self.target_y = self._generate_data()\n",
    "    \n",
    "    def _generate_data(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Generate all data at once and return fixed tensors.\n",
    "        \"\"\"\n",
    "        # Generate mean vectors for all tasks - Shape: (B, d)\n",
    "        mus = torch.randn(self.B, self.d)\n",
    "        # Normalize and scale - Shape: (B, d)\n",
    "        mus = mus / torch.norm(mus, dim=1, keepdim=True) * self.R\n",
    "        \n",
    "        # Generate clean labels at once - Shape: (B, N+1)\n",
    "        y_all = (torch.rand(self.B, self.N + 1) > 0.5).float()\n",
    "        \n",
    "        # Convert to {-1, 1} for signal generation - Shape: (B, N+1)\n",
    "        y_signal = 2 * y_all - 1\n",
    "        \n",
    "        # Generate noise - Shape: (B, N+1, d)\n",
    "        z = torch.randn(self.B, self.N + 1, self.d)\n",
    "        \n",
    "        # Create the mixture - Shape: (B, N+1, d)\n",
    "        x = y_signal[..., None] * mus[:, None, :] + z\n",
    "\n",
    "        # Flip labels with probability label_flip_p\n",
    "        if self.label_flip_p:\n",
    "            flip_mask = (torch.rand(self.B, self.N + 1) < self.label_flip_p)\n",
    "            y_all = torch.where(flip_mask, 1 - y_all, y_all)\n",
    "        \n",
    "        # Split into context and target\n",
    "        context_x = x[:, :self.N, :]  # (B, N, d)\n",
    "        target_x = x[:, -1, :]        # (B, d)\n",
    "        context_y = y_all[:, :self.N]  # (B, N)\n",
    "        target_y = y_all[:, -1]       # (B)\n",
    "        \n",
    "        return context_x, context_y, target_x, target_y\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return 1  # Only one batch for full-batch GD\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Return the entire dataset as one batch\"\"\"\n",
    "        assert idx == 0, \"Only one batch supported for full-batch GD\"\n",
    "        return self.context_x, self.context_y, self.target_x, self.target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "149c7865",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 59\u001b[0m\n\u001b[0;32m     50\u001b[0m             accuracies\u001b[38;5;241m.\u001b[39mappend(correct)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(accuracies) \u001b[38;5;28;01mif\u001b[39;00m accuracies \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_evaluated\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(accuracies),\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_failed\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset\u001b[38;5;241m.\u001b[39mB \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(accuracies)\n\u001b[0;32m     56\u001b[0m     }\n\u001b[0;32m     58\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_gmm_linear\u001b[39m(dataset: GaussianMixtureDataset, linear_model: \u001b[43mLinearTransformer\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate LinearTransformer model on GMM classification tasks.\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     context_x, context_y, target_x, target_y \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "def format_gmm_example(x: torch.Tensor, y: float) -> str:\n",
    "    \"\"\"Format a single example from the GMM dataset for the prompt\"\"\"\n",
    "    x_str = \", \".join(f\"{v:.6f}\" for v in x.tolist())\n",
    "    return f\"({x_str}) -> Class {int(y)}\"\n",
    "\n",
    "def build_prompt_gmm(context_x: torch.Tensor, context_y: torch.Tensor, \n",
    "                    target_x: torch.Tensor, batch_idx: int = 0) -> str:\n",
    "    \"\"\"\n",
    "    Build a prompt for the GMM classification task.\n",
    "    \n",
    "    Args:\n",
    "        context_x: Shape (B, N, d)\n",
    "        context_y: Shape (B, N)\n",
    "        target_x: Shape (B, d)\n",
    "        batch_idx: Which batch example to use\n",
    "    \"\"\"\n",
    "    header = \"You are solving a binary classification task.\\n\"\n",
    "    header += \"Each input x is a point in d-dimensional space, labeled as Class 0 or Class 1.\\n\"\n",
    "    header += \"Given the training examples, predict the class (0 or 1) for the new point.\\n\\n\"\n",
    "    \n",
    "    # Format context examples\n",
    "    lines = [format_gmm_example(context_x[batch_idx, i], context_y[batch_idx, i]) \n",
    "            for i in range(context_x.size(1))]\n",
    "    ctx = \"\\n\".join(lines)\n",
    "    \n",
    "    # Format target\n",
    "    x_test = \", \".join(f\"{v:.6f}\" for v in target_x[batch_idx].tolist())\n",
    "    \n",
    "    prompt = (\n",
    "        header\n",
    "        + \"Training examples (each line is '(x1, ..., xd) -> Class y'):\\n\"\n",
    "        + ctx + \"\\n\\n\"\n",
    "        + f\"Now predict the class for x_test = [{x_test}].\\n\"\n",
    "        + \"Respond with a single number (0 or 1) or JSON: {\\\"class\\\": 0/1}\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_gmm_llama(dataset: GaussianMixtureDataset) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate LLaMA model on GMM classification tasks.\"\"\"\n",
    "    context_x, context_y, target_x, target_y = dataset[0]\n",
    "    \n",
    "    accuracies = []\n",
    "    for i in range(dataset.B):\n",
    "        prompt = build_prompt_gmm(context_x, context_y, target_x, batch_idx=i)\n",
    "        output, pred = llama_predict(prompt)\n",
    "        if pred is not None:\n",
    "            pred = round(float(pred))\n",
    "            correct = int(pred == target_y[i].item())\n",
    "            accuracies.append(correct)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": np.mean(accuracies) if accuracies else float(\"nan\"),\n",
    "        \"n_evaluated\": len(accuracies),\n",
    "        \"n_failed\": dataset.B - len(accuracies)\n",
    "    }\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_gmm_linear(dataset: GaussianMixtureDataset, linear_model: LinearTransformer) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate LinearTransformer model on GMM classification tasks.\"\"\"\n",
    "    context_x, context_y, target_x, target_y = dataset[0]\n",
    "    \n",
    "    accuracies = []\n",
    "    in_context_accuracies = []\n",
    "    \n",
    "    for i in range(dataset.B):\n",
    "        # Prepare batch\n",
    "        batch_x = context_x[i:i+1].to(device)\n",
    "        batch_y = context_y[i:i+1].to(device)\n",
    "        batch_target = target_x[i:i+1].to(device)\n",
    "        \n",
    "        # Get prediction\n",
    "        logits = linear_model(batch_x, batch_y, batch_target)\n",
    "        pred = (logits > 0).float().item()\n",
    "        correct = int(pred == target_y[i].item())\n",
    "        accuracies.append(correct)\n",
    "        \n",
    "        # Get in-context predictions\n",
    "        in_context_preds = linear_model.compute_in_context_preds(batch_x, batch_y)\n",
    "        in_context_acc = (in_context_preds == batch_y).float().mean().item()\n",
    "        in_context_accuracies.append(in_context_acc)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": np.mean(accuracies),\n",
    "        \"in_context_accuracy\": np.mean(in_context_accuracies),\n",
    "        \"n_evaluated\": len(accuracies),\n",
    "        \"n_failed\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff78bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_gmm_llama(dataset: GaussianMixtureDataset) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate LLaMA model on GMM classification tasks.\"\"\"\n",
    "    context_x, context_y, target_x, target_y = dataset[0]\n",
    "    \n",
    "    accuracies = []\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for i in range(dataset.B):\n",
    "        # Create a more explicit prompt for binary classification\n",
    "        prompt = (\n",
    "            \"You are performing binary classification. Your task is to predict either class 0 or class 1.\\n\"\n",
    "            \"For each input point x, you must output EXACTLY 0 or 1.\\n\\n\"\n",
    "            \"Training examples (format: 'input -> class'):\\n\"\n",
    "        )\n",
    "        \n",
    "        # Add context examples\n",
    "        for j in range(context_x.size(1)):\n",
    "            x_str = \", \".join(f\"{v:.4f}\" for v in context_x[i, j])\n",
    "            y = int(context_y[i, j].item())\n",
    "            prompt += f\"[{x_str}] -> {y}\\n\"\n",
    "        \n",
    "        # Add target example with very explicit instruction\n",
    "        x_test_str = \", \".join(f\"{v:.4f}\" for v in target_x[i])\n",
    "        prompt += f\"\\nPredict the class (0 or 1) for: [{x_test_str}]\\n\"\n",
    "        prompt += \"Output ONLY the number 0 or 1 with no other text.\\n\"\n",
    "        \n",
    "        # Get prediction from model\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(device)\n",
    "        output = llama_model.generate(  # Using llama_model instead of model\n",
    "            **input_ids,\n",
    "            max_new_tokens=8,  # We only need a very short response\n",
    "            temperature=0.0,\n",
    "            top_p=1.0,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        text = tokenizer.decode(output[0][input_ids[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "        \n",
    "        # Parse output, being very strict about valid responses\n",
    "        try:\n",
    "            pred_str = text.strip().split()[0]  # Take first token only\n",
    "            if pred_str in ['0', '1']:\n",
    "                pred = int(pred_str)\n",
    "                correct = int(pred == target_y[i].item())\n",
    "                accuracies.append(correct)\n",
    "                predictions.append(pred)\n",
    "                true_labels.append(target_y[i].item())\n",
    "            else:\n",
    "                print(f\"Invalid prediction '{text}' - expected 0 or 1\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse model output: '{text}'\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": np.mean(accuracies) if accuracies else float(\"nan\"),\n",
    "        \"predictions\": predictions,\n",
    "        \"true_labels\": true_labels,\n",
    "        \"n_evaluated\": len(accuracies),\n",
    "        \"n_failed\": dataset.B - len(accuracies),\n",
    "        \"raw_outputs\": []  # For debugging if needed\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "381b99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gmm_linear(dataset, linear_model):\n",
    "    \"\"\"Evaluate LinearTransformer on GMM classification task\"\"\"\n",
    "    results = {\n",
    "        'accuracy': 0.0,\n",
    "        'predictions': [],\n",
    "        'true_labels': []\n",
    "    }\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_idx in range(len(dataset)):\n",
    "        x_context, y_context, x_target, y_target = dataset[batch_idx]\n",
    "        \n",
    "        # Move data to device\n",
    "        x_context = x_context.to(device)\n",
    "        y_context = y_context.to(device)\n",
    "        x_target = x_target.to(device)\n",
    "        y_target = y_target.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            predictions = linear_model(x_context, y_context, x_target)\n",
    "            \n",
    "            # Convert logits to binary predictions (threshold at 0.5)\n",
    "            binary_preds = (torch.sigmoid(predictions) > 0.5).float()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            correct = (binary_preds == y_target).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += len(y_target)\n",
    "            \n",
    "            # Store predictions and true labels\n",
    "            results['predictions'].extend(binary_preds.cpu().numpy().tolist())\n",
    "            results['true_labels'].extend(y_target.cpu().numpy().tolist())\n",
    "    \n",
    "    # Calculate final accuracy\n",
    "    results['accuracy'] = total_correct / total_samples\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e1f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GMM Classification with different Signal-to-Noise Ratios (R)\n",
      "======================================================================\n",
      "\n",
      "Signal-to-Noise Ratio (R) = 10.0\n",
      "----------------------------------------\n",
      "\n",
      "Evaluating LLaMA model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearTransformer' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Test both models\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating LLaMA model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m llama_results \u001b[38;5;241m=\u001b[39m \u001b[43meval_gmm_llama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Print detailed results for first few examples\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetailed LLaMA Results (first 3 examples):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\banga\\miniforge3\\envs\\dsc80\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[69], line 31\u001b[0m, in \u001b[0;36meval_gmm_llama\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get prediction from model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 31\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m(\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minput_ids,\n\u001b[0;32m     33\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,  \u001b[38;5;66;03m# We only need a very short response\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m     35\u001b[0m     top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     36\u001b[0m     eos_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m     37\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     39\u001b[0m text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m][input_ids[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Parse output, being very strict about valid responses\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\banga\\miniforge3\\envs\\dsc80\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearTransformer' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "# Test the GMM classification setup with modified parameters\n",
    "import json\n",
    "\n",
    "# Parameters from the paper, with adjustments\n",
    "d = 20      # dimension\n",
    "N = 20      # reduced context size (was 41)\n",
    "B = 10      # batch size\n",
    "R = 10.0    # increased signal-to-noise ratio (was 3.0)\n",
    "\n",
    "print(\"Testing GMM Classification with different Signal-to-Noise Ratios (R)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Try two different signal-to-noise ratios\n",
    "snr_values = [10.0, 20.0]\n",
    "for R in snr_values:\n",
    "    print(f\"\\nSignal-to-Noise Ratio (R) = {R}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Create fresh dataset for this SNR\n",
    "    dataset = GaussianMixtureDataset(d=d, N=N, B=B, R=R, is_validation=False)\n",
    "    \n",
    "    # Create linear transformer model (with a clear name)\n",
    "    linear_transformer = LinearTransformer(d=d).to(device)\n",
    "    \n",
    "    # Test both models\n",
    "    print(\"\\nEvaluating LLaMA model...\")\n",
    "    llama_results = eval_gmm_llama(dataset)\n",
    "    \n",
    "    # Print detailed results for first few examples\n",
    "    print(\"\\nDetailed LLaMA Results (first 3 examples):\")\n",
    "    for i in range(min(3, len(llama_results[\"predictions\"]))):\n",
    "        print(f\"Example {i + 1}:\")\n",
    "        print(f\"Predicted: {llama_results['predictions'][i]}\")\n",
    "        print(f\"True Label: {llama_results['true_labels'][i]}\")\n",
    "        print(f\"Correct: {llama_results['predictions'][i] == llama_results['true_labels'][i]}\\n\")\n",
    "    \n",
    "    print(\"Overall LLaMA Results:\", json.dumps(llama_results, indent=2))\n",
    "    \n",
    "    print(\"\\nEvaluating Linear Transformer...\")\n",
    "    linear_results = eval_gmm_linear(dataset, linear_transformer)\n",
    "    print(\"Linear Transformer Results:\", json.dumps(linear_results, indent=2))\n",
    "    \n",
    "    # Print summary comparison\n",
    "    print(\"\\nAccuracy Comparison:\")\n",
    "    print(f\"LLaMA Accuracy: {llama_results['accuracy']:.3f}\")\n",
    "    print(f\"Linear Transformer Accuracy: {linear_results['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83369734",
   "metadata": {},
   "source": [
    "# Linear Classification Implementation\n",
    "Below we implement a linear classification version similar to the paper's approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2ab48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "@dataclass\n",
    "class LinearClassificationTask:\n",
    "    W: np.ndarray         # shape: (1, d)\n",
    "    X: np.ndarray         # shape: (N, d)\n",
    "    y: np.ndarray         # shape: (N,)  # binary labels 0/1\n",
    "    x_test: np.ndarray    # shape: (d,)\n",
    "    y_test: float         # scalar (0 or 1)\n",
    "\n",
    "def sample_linear_classification_task(\n",
    "    d: int = D_DEFAULT,\n",
    "    N: Optional[int] = None,\n",
    "    alpha: float = 1.0,\n",
    "    rng: Optional[np.random.Generator] = None,\n",
    ") -> LinearClassificationTask:\n",
    "    \"\"\"\n",
    "    Sample a binary classification task:\n",
    "        y = 1 if W·x > 0 else 0,  x ~ U(-alpha, alpha)^d\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = rng_global\n",
    "    if N is None:\n",
    "        N = 2 * d + 1\n",
    "\n",
    "    # Teacher weights\n",
    "    W = rng.standard_normal(size=(1, d))\n",
    "    \n",
    "    # Context inputs\n",
    "    X = rng.uniform(-alpha, alpha, size=(N, d))\n",
    "    # Binary labels based on sign of W·x\n",
    "    y = (X @ W.T > 0).reshape(-1).astype(float)\n",
    "    \n",
    "    # Query example\n",
    "    x_test = rng.uniform(-alpha, alpha, size=(d,))\n",
    "    y_test = float(W @ x_test > 0)\n",
    "\n",
    "    return LinearClassificationTask(W=W, X=X, y=y, x_test=x_test, y_test=y_test)\n",
    "\n",
    "class LinearTransformer(nn.Module):\n",
    "    \"\"\"One-layer linear transformer model for binary classification\"\"\"\n",
    "    def __init__(self, d: int):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.zeros(d, d))\n",
    "\n",
    "    def _predict_single(self, context_x: torch.Tensor, context_y: torch.Tensor, \n",
    "                       target_x: torch.Tensor) -> torch.Tensor:\n",
    "        N = context_x.shape[1]\n",
    "        context_y_signal = 2 * context_y - 1\n",
    "        context_term = (1/N) * torch.sum(context_y_signal[..., None] * context_x, dim=1)\n",
    "        transformed = context_term @ self.W\n",
    "        logits = (transformed * target_x).sum(dim=1)\n",
    "        return logits\n",
    "\n",
    "    def forward(self, context_x: torch.Tensor, context_y: torch.Tensor, \n",
    "                target_x: torch.Tensor) -> torch.Tensor:\n",
    "        return self._predict_single(context_x, context_y, target_x)\n",
    "\n",
    "    def compute_in_context_preds(self, context_x: torch.Tensor, \n",
    "                                context_y: torch.Tensor) -> torch.Tensor:\n",
    "        B, N, d = context_x.shape\n",
    "        context_x = context_x / torch.norm(context_x, dim=2, keepdim=True)\n",
    "        context_y_signal = 2 * context_y - 1\n",
    "        hat_mu = (1/N) * torch.sum(context_y_signal[..., None] * context_x, dim=1)\n",
    "        transformed = hat_mu @ self.W\n",
    "        logits = transformed[:, None, :] @ context_x.transpose(-1, -2)\n",
    "        predictions = (logits[:, 0, :] > 0).float()\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce806e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Results: {\n",
      "  \"test_accuracy\": 0.7,\n",
      "  \"in_context_accuracy\": 0.4829268127679825\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\banga\\AppData\\Local\\Temp\\ipykernel_21872\\104579869.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y_test = float(W @ x_test > 0)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "linear_transformer = LinearTransformer(d=D_DEFAULT).to(device)\n",
    "\n",
    "def eval_classification_task(task: LinearClassificationTask, linear_transformer: LinearTransformer) -> Dict[str, float]:\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    context_x = torch.FloatTensor(task.X).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    context_y = torch.FloatTensor(task.y).unsqueeze(0).to(device)\n",
    "    target_x = torch.FloatTensor(task.x_test).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get model prediction\n",
    "    with torch.no_grad():\n",
    "        logits = linear_transformer(context_x, context_y, target_x)\n",
    "        pred = (logits > 0).float().item()\n",
    "    \n",
    "    # Compute accuracy\n",
    "    correct = int(pred == task.y_test)\n",
    "    \n",
    "    # Also get in-context predictions\n",
    "    in_context_preds = linear_transformer.compute_in_context_preds(context_x, context_y)\n",
    "    in_context_acc = (in_context_preds == context_y).float().mean().item()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": correct,\n",
    "        \"in_context_accuracy\": in_context_acc,\n",
    "        \"prediction\": pred,\n",
    "        \"target\": task.y_test\n",
    "    }\n",
    "\n",
    "# Test on a batch of tasks\n",
    "n_eval_tasks = 10\n",
    "results = []\n",
    "for _ in range(n_eval_tasks):\n",
    "    task = sample_linear_classification_task(d=D_DEFAULT, N=None, alpha=1.0)\n",
    "    res = eval_classification_task(task, linear_transformer)\n",
    "    results.append(res)\n",
    "\n",
    "# Compute average metrics\n",
    "avg_metrics = {\n",
    "    \"test_accuracy\": np.mean([r[\"accuracy\"] for r in results]),\n",
    "    \"in_context_accuracy\": np.mean([r[\"in_context_accuracy\"] for r in results])\n",
    "}\n",
    "print(\"Classification Results:\", json.dumps(avg_metrics, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12905496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
